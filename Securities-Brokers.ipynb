{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "926509e1",
   "metadata": {},
   "source": [
    "## Code format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2477b48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# Code format\\n# For Jupyter Notebook:\\n%load_ext nb_black\\n# For Jupyter Lab:\\n# %load_ext lab_black\";\n",
       "                var nbb_formatted_code = \"# Code format\\n# For Jupyter Notebook:\\n%load_ext nb_black\\n# For Jupyter Lab:\\n# %load_ext lab_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code format\n",
    "# For Jupyter Notebook:\n",
    "%load_ext nb_black\n",
    "# For Jupyter Lab:\n",
    "# %load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e3bb9b",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "441875bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# Converting documents from one format to another\\nimport pypandoc\\n\\n# General purpose libraries\\nimport os\\nimport time\\nimport sys\\n\\n# Data management tools\\n# Serialization and deserialization of Python objects\\nimport pickle\\nimport json\";\n",
       "                var nbb_formatted_code = \"# Converting documents from one format to another\\nimport pypandoc\\n\\n# General purpose libraries\\nimport os\\nimport time\\nimport sys\\n\\n# Data management tools\\n# Serialization and deserialization of Python objects\\nimport pickle\\nimport json\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Converting documents from one format to another\n",
    "import pypandoc\n",
    "\n",
    "# General purpose libraries\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Data management tools\n",
    "# Serialization and deserialization of Python objects\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf917495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"import openai\\nfrom transformers import GPT2Tokenizer\";\n",
       "                var nbb_formatted_code = \"import openai\\nfrom transformers import GPT2Tokenizer\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tools for interacting with the OpenAI API\n",
    "import openai\n",
    "# Tools for working with various pre-trained language models\n",
    "# Includes tokenizers and other utilities for text processing\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5e91cea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 113;\n",
       "                var nbb_unformatted_code = \"# Libraries and classes to load and parse different types of text data\\nfrom langchain.document_loaders import (\\n    UnstructuredPDFLoader,\\n    OnlinePDFLoader,\\n    UnstructuredFileLoader,\\n    TextLoader,\\n    PyPDFLoader,\\n)\\n\\n# Classes for splitting text into characters and recursively splitting text into characters\\n# Tools for splitting text into smaller chunks for further processing\\nfrom langchain.text_splitter import (\\n    CharacterTextSplitter,\\n    RecursiveCharacterTextSplitter,\\n)\\n\\n# Tools for working with OpenAI's GPT-3 language model\\n# from langchain.embeddings import OpenAIEmbeddings\\nfrom langchain.embeddings.openai import OpenAIEmbeddings\\n\\n# Tools for working with vector databases, including authentication with the Pinecone and OpenAI APIs\\n# from langchain.vectorstores import Chroma, Pinecone\\n# from langchain.vectorstores.faiss import FAISS\\nfrom langchain.vectorstores import (\\n    Chroma,\\n    Pinecone,\\n    ElasticVectorSearch,\\n    Weaviate,\\n    FAISS,\\n)\\n\\n# Wrapper around OpenAI's API and provides tools for interacting with OpenAI's GPT-3 language model\\nfrom langchain.llms import OpenAI\\n\\n# Tools for building and running natural language processing (NLP) chains\\n# Class for building a retrieval-based question answering (QA) system and chatbots that interact with vector databases\\nfrom langchain.chains import (\\n    RetrievalQA,\\n    ChatVectorDBChain,\\n    ConversationalRetrievalChain,\\n)\\n\\n# Generating text prompts\\nfrom langchain.prompts.prompt import PromptTemplate\\n\\n# Load question answering chain\\nfrom langchain.chains.question_answering import load_qa_chain\\n\\n# Class to create indexes in vector databases\\nfrom langchain.indexes import VectorstoreIndexCreator\";\n",
       "                var nbb_formatted_code = \"# Libraries and classes to load and parse different types of text data\\nfrom langchain.document_loaders import (\\n    UnstructuredPDFLoader,\\n    OnlinePDFLoader,\\n    UnstructuredFileLoader,\\n    TextLoader,\\n    PyPDFLoader,\\n)\\n\\n# Classes for splitting text into characters and recursively splitting text into characters\\n# Tools for splitting text into smaller chunks for further processing\\nfrom langchain.text_splitter import (\\n    CharacterTextSplitter,\\n    RecursiveCharacterTextSplitter,\\n)\\n\\n# Tools for working with OpenAI's GPT-3 language model\\n# from langchain.embeddings import OpenAIEmbeddings\\nfrom langchain.embeddings.openai import OpenAIEmbeddings\\n\\n# Tools for working with vector databases, including authentication with the Pinecone and OpenAI APIs\\n# from langchain.vectorstores import Chroma, Pinecone\\n# from langchain.vectorstores.faiss import FAISS\\nfrom langchain.vectorstores import (\\n    Chroma,\\n    Pinecone,\\n    ElasticVectorSearch,\\n    Weaviate,\\n    FAISS,\\n)\\n\\n# Wrapper around OpenAI's API and provides tools for interacting with OpenAI's GPT-3 language model\\nfrom langchain.llms import OpenAI\\n\\n# Tools for building and running natural language processing (NLP) chains\\n# Class for building a retrieval-based question answering (QA) system and chatbots that interact with vector databases\\nfrom langchain.chains import (\\n    RetrievalQA,\\n    ChatVectorDBChain,\\n    ConversationalRetrievalChain,\\n)\\n\\n# Generating text prompts\\nfrom langchain.prompts.prompt import PromptTemplate\\n\\n# Load question answering chain\\nfrom langchain.chains.question_answering import load_qa_chain\\n\\n# Class to create indexes in vector databases\\nfrom langchain.indexes import VectorstoreIndexCreator\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Libraries and classes to load and parse different types of text data\n",
    "from langchain.document_loaders import (\n",
    "    UnstructuredPDFLoader,\n",
    "    OnlinePDFLoader,\n",
    "    UnstructuredFileLoader,\n",
    "    TextLoader,\n",
    "    PyPDFLoader,\n",
    ")\n",
    "\n",
    "# Classes for splitting text into characters and recursively splitting text into characters\n",
    "# Tools for splitting text into smaller chunks for further processing\n",
    "from langchain.text_splitter import (\n",
    "    CharacterTextSplitter,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "\n",
    "# Tools for working with OpenAI's GPT-3 language model\n",
    "# from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Tools for working with vector databases, including authentication with the Pinecone and OpenAI APIs\n",
    "# from langchain.vectorstores import Chroma, Pinecone\n",
    "# from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.vectorstores import (\n",
    "    Chroma,\n",
    "    Pinecone,\n",
    "    ElasticVectorSearch,\n",
    "    Weaviate,\n",
    "    FAISS,\n",
    ")\n",
    "\n",
    "# Wrapper around OpenAI's API and provides tools for interacting with OpenAI's GPT-3 language model\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Tools for building and running natural language processing (NLP) chains\n",
    "# Class for building a retrieval-based question answering (QA) system and chatbots that interact with vector databases\n",
    "from langchain.chains import (\n",
    "    RetrievalQA,\n",
    "    ChatVectorDBChain,\n",
    "    ConversationalRetrievalChain,\n",
    ")\n",
    "\n",
    "# Generating text prompts\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "# Load question answering chain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "# Class to create indexes in vector databases\n",
    "from langchain.indexes import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b898e1",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dda5f515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 76;\n",
       "                var nbb_unformatted_code = \"# Function to save an object into a pickle file.\\ndef f_pklsave(arg_obj, arg_path: str):\\n    \\\"\\\"\\\"\\n    Serialize and save the given object to a pickle file at the specified path.\\n\\n    Parameters:\\n    arg_obj (object): The object that needs to be saved in the pickle file.\\n    arg_path (str): The file path of the pickle file where the object will be saved.\\n\\n    Returns:\\n    None\\n\\n    Example:\\n    >>> my_object = {\\\"name\\\": \\\"John\\\", \\\"age\\\": 25, \\\"address\\\": \\\"123 Main St\\\"}\\n    >>> file_path = \\\"./my_object.pkl\\\"\\n    >>> f_pklsave(my_object, file_path)\\n    \\\"\\\"\\\"\\n    # Dump object to pickle file\\n    pickle.dump(arg_obj, open(arg_path, \\\"wb\\\"))\";\n",
       "                var nbb_formatted_code = \"# Function to save an object into a pickle file.\\ndef f_pklsave(arg_obj, arg_path: str):\\n    \\\"\\\"\\\"\\n    Serialize and save the given object to a pickle file at the specified path.\\n\\n    Parameters:\\n    arg_obj (object): The object that needs to be saved in the pickle file.\\n    arg_path (str): The file path of the pickle file where the object will be saved.\\n\\n    Returns:\\n    None\\n\\n    Example:\\n    >>> my_object = {\\\"name\\\": \\\"John\\\", \\\"age\\\": 25, \\\"address\\\": \\\"123 Main St\\\"}\\n    >>> file_path = \\\"./my_object.pkl\\\"\\n    >>> f_pklsave(my_object, file_path)\\n    \\\"\\\"\\\"\\n    # Dump object to pickle file\\n    pickle.dump(arg_obj, open(arg_path, \\\"wb\\\"))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to save an object into a pickle file.\n",
    "def f_pklsave(arg_obj, arg_path: str):\n",
    "    \"\"\"\n",
    "    Serialize and save the given object to a pickle file at the specified path.\n",
    "\n",
    "    Parameters:\n",
    "    arg_obj (object): The object that needs to be saved in the pickle file.\n",
    "    arg_path (str): The file path of the pickle file where the object will be saved.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Example:\n",
    "    >>> my_object = {\"name\": \"John\", \"age\": 25, \"address\": \"123 Main St\"}\n",
    "    >>> file_path = \"./my_object.pkl\"\n",
    "    >>> f_pklsave(my_object, file_path)\n",
    "    \"\"\"\n",
    "    # Dump object to pickle file\n",
    "    pickle.dump(arg_obj, open(arg_path, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b08b3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Function: Group the shorter chunks into chunks of around 1000 tokens and decrease the frequency of breaks within the text\\ndef group_chunks(chunks, ntokens, max_len=1000):\\n    \\\"\\\"\\\"\\n    Group very short chunks, to form approximately a page long chunks.\\n\\n    Args:\\n        chunks (List[str]): A list of string chunks to group.\\n        ntokens (List[int]): A list of integer number of tokens in each chunk.\\n        max_len (int): Maximum number of tokens to group together.\\n\\n    Returns:\\n        List[str]: A list of grouped string chunks.\\n    \\\"\\\"\\\"\\n\\n    batches = []  # initialize a list to store the grouped chunks\\n    cur_batch = (\\n        \\\"\\\"  # initialize an empty string to keep track of current group of chunks\\n    )\\n    cur_tokens = 0  # initialize a counter for number of tokens\\n\\n    # iterate over the chunks and group them based on token count\\n    for chunk, ntoken in zip(chunks, ntokens):\\n        cur_tokens += (\\n            ntoken + 2\\n        )  # increment the token count for current chunk (+2 for newlines between chunks)\\n\\n        # if adding this chunk would exceed the max length, finalize the current batch and start a new one\\n        if ntoken + cur_tokens > max_len:\\n            batches.append(cur_batch)  # add the current batch to the list of batches\\n            cur_batch = chunk  # start a new batch with the current chunk\\n        else:\\n            cur_batch += \\\"\\\\n\\\\n\\\" + chunk  # add the current chunk to the current batch\\n\\n    batches.append(cur_batch)  # add the last batch to the list of batches\\n    return batches  # return the list of grouped chunks\";\n",
       "                var nbb_formatted_code = \"# Function: Group the shorter chunks into chunks of around 1000 tokens and decrease the frequency of breaks within the text\\ndef group_chunks(chunks, ntokens, max_len=1000):\\n    \\\"\\\"\\\"\\n    Group very short chunks, to form approximately a page long chunks.\\n\\n    Args:\\n        chunks (List[str]): A list of string chunks to group.\\n        ntokens (List[int]): A list of integer number of tokens in each chunk.\\n        max_len (int): Maximum number of tokens to group together.\\n\\n    Returns:\\n        List[str]: A list of grouped string chunks.\\n    \\\"\\\"\\\"\\n\\n    batches = []  # initialize a list to store the grouped chunks\\n    cur_batch = (\\n        \\\"\\\"  # initialize an empty string to keep track of current group of chunks\\n    )\\n    cur_tokens = 0  # initialize a counter for number of tokens\\n\\n    # iterate over the chunks and group them based on token count\\n    for chunk, ntoken in zip(chunks, ntokens):\\n        cur_tokens += (\\n            ntoken + 2\\n        )  # increment the token count for current chunk (+2 for newlines between chunks)\\n\\n        # if adding this chunk would exceed the max length, finalize the current batch and start a new one\\n        if ntoken + cur_tokens > max_len:\\n            batches.append(cur_batch)  # add the current batch to the list of batches\\n            cur_batch = chunk  # start a new batch with the current chunk\\n        else:\\n            cur_batch += \\\"\\\\n\\\\n\\\" + chunk  # add the current chunk to the current batch\\n\\n    batches.append(cur_batch)  # add the last batch to the list of batches\\n    return batches  # return the list of grouped chunks\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function: Group the shorter chunks into chunks of around 1000 tokens and decrease the frequency of breaks within the text\n",
    "def group_chunks(chunks, ntokens, max_len=1000):\n",
    "    \"\"\"\n",
    "    Group very short chunks, to form approximately a page long chunks.\n",
    "\n",
    "    Args:\n",
    "        chunks (List[str]): A list of string chunks to group.\n",
    "        ntokens (List[int]): A list of integer number of tokens in each chunk.\n",
    "        max_len (int): Maximum number of tokens to group together.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of grouped string chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    batches = []  # initialize a list to store the grouped chunks\n",
    "    cur_batch = (\n",
    "        \"\"  # initialize an empty string to keep track of current group of chunks\n",
    "    )\n",
    "    cur_tokens = 0  # initialize a counter for number of tokens\n",
    "\n",
    "    # iterate over the chunks and group them based on token count\n",
    "    for chunk, ntoken in zip(chunks, ntokens):\n",
    "        cur_tokens += (\n",
    "            ntoken + 2\n",
    "        )  # increment the token count for current chunk (+2 for newlines between chunks)\n",
    "\n",
    "        # if adding this chunk would exceed the max length, finalize the current batch and start a new one\n",
    "        if ntoken + cur_tokens > max_len:\n",
    "            batches.append(cur_batch)  # add the current batch to the list of batches\n",
    "            cur_batch = chunk  # start a new batch with the current chunk\n",
    "        else:\n",
    "            cur_batch += \"\\n\\n\" + chunk  # add the current chunk to the current batch\n",
    "\n",
    "    batches.append(cur_batch)  # add the last batch to the list of batches\n",
    "    return batches  # return the list of grouped chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "752746f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Function: Translate each chunck of text to english\\ndef translate_chunk(chunk, engine=\\\"text-davinci-002\\\", dest_language=\\\"English\\\"):\\n    \\\"\\\"\\\"\\n    Translate the input chunk to the specified destination language using OpenAI GPT-3 API.\\n\\n    Args:\\n        chunk (str): The input text to be translated.\\n        engine (str): The GPT-3 engine ID to use for the translation.\\n        dest_language (str): The destination language to translate the input text to.\\n\\n    Returns:\\n        str: The translated text.\\n    \\\"\\\"\\\"\\n    # Generate the prompt to be sent to the OpenAI API\\n    prompt = f'''Translate only the text from the following text document into {dest_language}.\\n\\\"\\\"\\\"{chunk}\\\"\\\"\\\"\\n'''\\n\\n    # Send a request to the OpenAI API to translate the chunk\\n    response = openai.Completion.create(\\n        prompt=prompt,\\n        engine=engine,\\n        temperature=0,\\n        top_p=1,\\n        max_tokens=1500,\\n    )\\n\\n    # Extract the translated text from the API response\\n    result = response[\\\"choices\\\"][0][\\\"text\\\"].strip()\\n    # Remove the double quotes, as we used them to surround the text in the prompt\\n    result = result.replace('\\\"\\\"\\\"', \\\"\\\")\\n    # Return the translated text\\n    return result\";\n",
       "                var nbb_formatted_code = \"# Function: Translate each chunck of text to english\\ndef translate_chunk(chunk, engine=\\\"text-davinci-002\\\", dest_language=\\\"English\\\"):\\n    \\\"\\\"\\\"\\n    Translate the input chunk to the specified destination language using OpenAI GPT-3 API.\\n\\n    Args:\\n        chunk (str): The input text to be translated.\\n        engine (str): The GPT-3 engine ID to use for the translation.\\n        dest_language (str): The destination language to translate the input text to.\\n\\n    Returns:\\n        str: The translated text.\\n    \\\"\\\"\\\"\\n    # Generate the prompt to be sent to the OpenAI API\\n    prompt = f'''Translate only the text from the following text document into {dest_language}.\\n\\\"\\\"\\\"{chunk}\\\"\\\"\\\"\\n'''\\n\\n    # Send a request to the OpenAI API to translate the chunk\\n    response = openai.Completion.create(\\n        prompt=prompt,\\n        engine=engine,\\n        temperature=0,\\n        top_p=1,\\n        max_tokens=1500,\\n    )\\n\\n    # Extract the translated text from the API response\\n    result = response[\\\"choices\\\"][0][\\\"text\\\"].strip()\\n    # Remove the double quotes, as we used them to surround the text in the prompt\\n    result = result.replace('\\\"\\\"\\\"', \\\"\\\")\\n    # Return the translated text\\n    return result\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function: Translate each chunck of text to english\n",
    "def translate_chunk(chunk, engine=\"text-davinci-002\", dest_language=\"English\"):\n",
    "    \"\"\"\n",
    "    Translate the input chunk to the specified destination language using OpenAI GPT-3 API.\n",
    "\n",
    "    Args:\n",
    "        chunk (str): The input text to be translated.\n",
    "        engine (str): The GPT-3 engine ID to use for the translation.\n",
    "        dest_language (str): The destination language to translate the input text to.\n",
    "\n",
    "    Returns:\n",
    "        str: The translated text.\n",
    "    \"\"\"\n",
    "    # Generate the prompt to be sent to the OpenAI API\n",
    "    prompt = f'''Translate only the text from the following text document into {dest_language}.\n",
    "\"\"\"{chunk}\"\"\"\n",
    "'''\n",
    "\n",
    "    # Send a request to the OpenAI API to translate the chunk\n",
    "    response = openai.Completion.create(\n",
    "        prompt=prompt,\n",
    "        engine=engine,\n",
    "        temperature=0,\n",
    "        top_p=1,\n",
    "        max_tokens=1500,\n",
    "    )\n",
    "\n",
    "    # Extract the translated text from the API response\n",
    "    result = response[\"choices\"][0][\"text\"].strip()\n",
    "    # Remove the double quotes, as we used them to surround the text in the prompt\n",
    "    result = result.replace('\"\"\"', \"\")\n",
    "    # Return the translated text\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124511bf",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a3173da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# Folder paths\\nstr_folder_credentials = \\\"credentials/\\\"\\nstr_folder_sources = \\\"sources/\\\"\\nstr_folder_outputs = \\\"outputs/\\\"\";\n",
       "                var nbb_formatted_code = \"# Folder paths\\nstr_folder_credentials = \\\"credentials/\\\"\\nstr_folder_sources = \\\"sources/\\\"\\nstr_folder_outputs = \\\"outputs/\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Folder paths\n",
    "str_folder_credentials = \"credentials/\"\n",
    "str_folder_sources = \"sources/\"\n",
    "str_folder_outputs = \"outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecbac295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSMV00001500034003.docx']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# List files\\nlst_pdfs = [x for x in os.listdir(str_folder_sources) if x.endswith(\\\".docx\\\")]\\nlst_pdfs\";\n",
       "                var nbb_formatted_code = \"# List files\\nlst_pdfs = [x for x in os.listdir(str_folder_sources) if x.endswith(\\\".docx\\\")]\\nlst_pdfs\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List files\n",
    "lst_pdfs = [x for x in os.listdir(str_folder_sources) if x.endswith(\".docx\")]\n",
    "lst_pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b13baff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# Filename, with and without extension\\nsrt_filename = lst_pdfs[0]\\nsrt_filename_next = srt_filename.split(\\\".\\\")[0]\";\n",
       "                var nbb_formatted_code = \"# Filename, with and without extension\\nsrt_filename = lst_pdfs[0]\\nsrt_filename_next = srt_filename.split(\\\".\\\")[0]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filename, with and without extension\n",
    "srt_filename = lst_pdfs[0]\n",
    "srt_filename_next = srt_filename.split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21b1b8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Filename and folders\\nstr_path_input = str_folder_sources + srt_filename\\nstr_path_output_pkl = str_folder_outputs + srt_filename_next + \\\".pkl\\\"\\nstr_path_output_txt = str_folder_outputs + srt_filename_next + \\\".txt\\\"\\nstr_path_output_txt_en = str_folder_outputs + srt_filename_next + \\\"_en.txt\\\"\";\n",
       "                var nbb_formatted_code = \"# Filename and folders\\nstr_path_input = str_folder_sources + srt_filename\\nstr_path_output_pkl = str_folder_outputs + srt_filename_next + \\\".pkl\\\"\\nstr_path_output_txt = str_folder_outputs + srt_filename_next + \\\".txt\\\"\\nstr_path_output_txt_en = str_folder_outputs + srt_filename_next + \\\"_en.txt\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filename and folders\n",
    "str_path_input = str_folder_sources + srt_filename\n",
    "str_path_output_pkl = str_folder_outputs + srt_filename_next + \".pkl\"\n",
    "str_path_output_txt = str_folder_outputs + srt_filename_next + \".txt\"\n",
    "str_path_output_txt_en = str_folder_outputs + srt_filename_next + \"_en.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bea75a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('RSMV00001500034003.docx',\n",
       " 'sources/RSMV00001500034003.docx',\n",
       " 'outputs/RSMV00001500034003.pkl',\n",
       " 'outputs/RSMV00001500034003.txt',\n",
       " 'outputs/RSMV00001500034003_en.txt')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"srt_filename, str_path_input, str_path_output_pkl, str_path_output_txt, str_path_output_txt_en\";\n",
       "                var nbb_formatted_code = \"srt_filename, str_path_input, str_path_output_pkl, str_path_output_txt, str_path_output_txt_en\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "srt_filename, str_path_input, str_path_output_pkl, str_path_output_txt, str_path_output_txt_en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a01b3e",
   "metadata": {},
   "source": [
    "### Authentication for APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7726c052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# Load credentials\\n# Create dictionary to store credentials\\nlst_cred = {}\\n# Loop through folder and load json file with credentials\\nfor x in [x for x in os.listdir(str_folder_credentials)]:\\n    lst_cred[x.split(\\\".\\\")[0]] = json.load(open(str_folder_credentials + x, \\\"r\\\"))\";\n",
       "                var nbb_formatted_code = \"# Load credentials\\n# Create dictionary to store credentials\\nlst_cred = {}\\n# Loop through folder and load json file with credentials\\nfor x in [x for x in os.listdir(str_folder_credentials)]:\\n    lst_cred[x.split(\\\".\\\")[0]] = json.load(open(str_folder_credentials + x, \\\"r\\\"))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load credentials\n",
    "# Create dictionary to store credentials\n",
    "lst_cred = {}\n",
    "# Loop through folder and load json file with credentials\n",
    "for x in [x for x in os.listdir(str_folder_credentials)]:\n",
    "    lst_cred[x.split(\".\")[0]] = json.load(open(str_folder_credentials + x, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36ec658d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"OPENAI_API_KEY = lst_cred[\\\"yahoo\\\"][\\\"OPENAI_API_KEY\\\"]\\nPINECONE_API_KEY = lst_cred[\\\"mail\\\"][\\\"PINECONE_API_KEY\\\"]\\nPINECONE_API_ENV = lst_cred[\\\"yahoo\\\"][\\\"PINECONE_API_ENV\\\"]\";\n",
       "                var nbb_formatted_code = \"OPENAI_API_KEY = lst_cred[\\\"yahoo\\\"][\\\"OPENAI_API_KEY\\\"]\\nPINECONE_API_KEY = lst_cred[\\\"mail\\\"][\\\"PINECONE_API_KEY\\\"]\\nPINECONE_API_ENV = lst_cred[\\\"yahoo\\\"][\\\"PINECONE_API_ENV\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OPENAI_API_KEY = lst_cred[\"yahoo\"][\"OPENAI_API_KEY\"]\n",
    "PINECONE_API_KEY = lst_cred[\"mail\"][\"PINECONE_API_KEY\"]\n",
    "PINECONE_API_ENV = lst_cred[\"yahoo\"][\"PINECONE_API_ENV\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8187d3f9",
   "metadata": {},
   "source": [
    "## Method 1: Translating the document to english"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b7eec2",
   "metadata": {},
   "source": [
    "### Ingestion of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a1a8506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"openai.api_key = OPENAI_API_KEY\";\n",
       "                var nbb_formatted_code = \"openai.api_key = OPENAI_API_KEY\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load credentials for OpenAI\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad9d4ae",
   "metadata": {},
   "source": [
    "#### docx to txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6b39fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"pypandoc.convert_file(str_path_input, \\\"plain\\\", outputfile=str_path_output_txt)\";\n",
       "                var nbb_formatted_code = \"pypandoc.convert_file(str_path_input, \\\"plain\\\", outputfile=str_path_output_txt)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the txt file to plain text format and save it as a new file\n",
    "pypandoc.convert_file(str_path_input, \"plain\", outputfile=str_path_output_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cdc5da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"str_text_raw = open(str_path_output_txt, mode=\\\"r\\\", encoding=\\\"utf8\\\").read()\";\n",
       "                var nbb_formatted_code = \"str_text_raw = open(str_path_output_txt, mode=\\\"r\\\", encoding=\\\"utf8\\\").read()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read converted text \n",
    "str_text_raw = open(str_path_output_txt, mode=\"r\", encoding=\"utf8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "08c20231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 125;\n",
       "                var nbb_unformatted_code = \"# Load spanish file\\nloader_es = TextLoader(str_path_output_txt, encoding=\\\"utf8\\\")\";\n",
       "                var nbb_formatted_code = \"# Load spanish file\\nloader_es = TextLoader(str_path_output_txt, encoding=\\\"utf8\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load spanish file\n",
    "loader_es = TextLoader(str_path_output_txt, encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d962cd",
   "metadata": {},
   "source": [
    "####  Count and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86f7a2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89a353c458247d5a8757239535cc52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8357b9b40374c8c90dd0cba807a070d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecad3ad9e0fa416ca77a1f7ff7e747c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"# OpenAI GPT-2 tokenizer is the same as GPT-3 tokenizer\\n# we use it to count the number of tokens in the text\\ntokenizer = GPT2Tokenizer.from_pretrained(\\\"gpt2\\\")\";\n",
       "                var nbb_formatted_code = \"# OpenAI GPT-2 tokenizer is the same as GPT-3 tokenizer\\n# we use it to count the number of tokens in the text\\ntokenizer = GPT2Tokenizer.from_pretrained(\\\"gpt2\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the GPT2Tokenizer from the transformers library and create an instance of the tokenizer using the GPT-2 model\n",
    "# OpenAI GPT-2 tokenizer is the same as GPT-3 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1eac9757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8263"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"chunks = str_text_raw.split(\\\"\\\\n\\\\n\\\")\\nntokens = []\\nfor chunk in chunks:\\n    ntokens.append(len(tokenizer.encode(chunk)))\\nmax(ntokens)\";\n",
       "                var nbb_formatted_code = \"chunks = str_text_raw.split(\\\"\\\\n\\\\n\\\")\\nntokens = []\\nfor chunk in chunks:\\n    ntokens.append(len(tokenizer.encode(chunk)))\\nmax(ntokens)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split the input text by double line breaks\n",
    "chunks = str_text_raw.split(\"\\n\\n\")\n",
    "\n",
    "# initialize an empty list to store the number of tokens in each chunk\n",
    "ntokens = []\n",
    "\n",
    "# iterate over the chunks and calculate the number of tokens in each one using the GPT2 tokenizer\n",
    "for chunk in chunks:\n",
    "    ntokens.append(len(tokenizer.encode(chunk)))\n",
    "\n",
    "# find the maximum number of tokens in any chunk\n",
    "max(ntokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bb448cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1709"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"chunks = group_chunks(chunks, ntokens)\\nlen(chunks)\";\n",
       "                var nbb_formatted_code = \"chunks = group_chunks(chunks, ntokens)\\nlen(chunks)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chunks = group_chunks(chunks, ntokens)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f8b4b9",
   "metadata": {},
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abfbc7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El Agente debe contar con un sistema de control que cumpla con las\\ndisposiciones contenidas en el presente Reglamento y con las demás\\ndisposiciones que aprueba la SMV.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"chunks[803]\";\n",
       "                var nbb_formatted_code = \"chunks[803]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chunks[803]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5437e3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Agent must have a control system that complies with the provisions contained in this Regulation and with the other provisions approved by the SMV.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"print(translate_chunk(chunks[803]))\";\n",
       "                var nbb_formatted_code = \"print(translate_chunk(chunks[803]))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(translate_chunk(chunks[803]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dcf5b5",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "598dd23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 1709\n",
      "2 / 1709\n",
      "3 / 1709\n",
      "4 / 1709\n",
      "5 / 1709\n",
      "6 / 1709\n",
      "7 / 1709\n",
      "8 / 1709\n",
      "9 / 1709\n",
      "10 / 1709\n",
      "11 / 1709\n",
      "12 / 1709\n",
      "13 / 1709\n",
      "14 / 1709\n",
      "15 / 1709\n",
      "16 / 1709\n",
      "17 / 1709\n",
      "18 / 1709\n",
      "19 / 1709\n",
      "20 / 1709\n",
      "21 / 1709\n",
      "22 / 1709\n",
      "23 / 1709\n",
      "24 / 1709\n",
      "25 / 1709\n",
      "26 / 1709\n",
      "27 / 1709\n",
      "28 / 1709\n",
      "29 / 1709\n",
      "30 / 1709\n",
      "31 / 1709\n",
      "32 / 1709\n",
      "33 / 1709\n",
      "34 / 1709\n",
      "35 / 1709\n",
      "36 / 1709\n",
      "37 / 1709\n",
      "38 / 1709\n",
      "39 / 1709\n",
      "40 / 1709\n",
      "41 / 1709\n",
      "42 / 1709\n",
      "43 / 1709\n",
      "44 / 1709\n",
      "45 / 1709\n",
      "46 / 1709\n",
      "47 / 1709\n",
      "48 / 1709\n",
      "49 / 1709\n",
      "50 / 1709\n",
      "51 / 1709\n",
      "52 / 1709\n",
      "53 / 1709\n",
      "54 / 1709\n",
      "55 / 1709\n",
      "56 / 1709\n",
      "57 / 1709\n",
      "58 / 1709\n",
      "59 / 1709\n",
      "60 / 1709\n",
      "61 / 1709\n",
      "62 / 1709\n",
      "63 / 1709\n",
      "64 / 1709\n",
      "65 / 1709\n",
      "66 / 1709\n",
      "67 / 1709\n",
      "68 / 1709\n",
      "69 / 1709\n",
      "70 / 1709\n",
      "71 / 1709\n",
      "72 / 1709\n",
      "73 / 1709\n",
      "74 / 1709\n",
      "75 / 1709\n",
      "76 / 1709\n",
      "77 / 1709\n",
      "78 / 1709\n",
      "79 / 1709\n",
      "80 / 1709\n",
      "81 / 1709\n",
      "82 / 1709\n",
      "83 / 1709\n",
      "84 / 1709\n",
      "85 / 1709\n",
      "86 / 1709\n",
      "87 / 1709\n",
      "88 / 1709\n",
      "89 / 1709\n",
      "90 / 1709\n",
      "91 / 1709\n",
      "92 / 1709\n",
      "93 / 1709\n",
      "94 / 1709\n",
      "95 / 1709\n",
      "96 / 1709\n",
      "97 / 1709\n",
      "98 / 1709\n",
      "99 / 1709\n",
      "100 / 1709\n",
      "101 / 1709\n",
      "102 / 1709\n",
      "103 / 1709\n",
      "104 / 1709\n",
      "105 / 1709\n",
      "106 / 1709\n",
      "107 / 1709\n",
      "108 / 1709\n",
      "109 / 1709\n",
      "110 / 1709\n",
      "111 / 1709\n",
      "112 / 1709\n",
      "113 / 1709\n",
      "114 / 1709\n",
      "115 / 1709\n",
      "116 / 1709\n",
      "117 / 1709\n",
      "118 / 1709\n",
      "119 / 1709\n",
      "120 / 1709\n",
      "121 / 1709\n",
      "122 / 1709\n",
      "123 / 1709\n",
      "124 / 1709\n",
      "125 / 1709\n",
      "126 / 1709\n",
      "127 / 1709\n",
      "128 / 1709\n",
      "129 / 1709\n",
      "130 / 1709\n",
      "131 / 1709\n",
      "132 / 1709\n",
      "133 / 1709\n",
      "134 / 1709\n",
      "135 / 1709\n",
      "136 / 1709\n",
      "137 / 1709\n",
      "138 / 1709\n",
      "139 / 1709\n",
      "140 / 1709\n",
      "141 / 1709\n",
      "142 / 1709\n",
      "143 / 1709\n",
      "144 / 1709\n",
      "145 / 1709\n",
      "146 / 1709\n",
      "147 / 1709\n",
      "148 / 1709\n",
      "149 / 1709\n",
      "150 / 1709\n",
      "151 / 1709\n",
      "152 / 1709\n",
      "153 / 1709\n",
      "154 / 1709\n",
      "155 / 1709\n",
      "156 / 1709\n",
      "157 / 1709\n",
      "158 / 1709\n",
      "159 / 1709\n",
      "160 / 1709\n",
      "161 / 1709\n",
      "162 / 1709\n",
      "163 / 1709\n",
      "164 / 1709\n",
      "165 / 1709\n",
      "166 / 1709\n",
      "167 / 1709\n",
      "168 / 1709\n",
      "169 / 1709\n",
      "170 / 1709\n",
      "171 / 1709\n",
      "172 / 1709\n",
      "173 / 1709\n",
      "174 / 1709\n",
      "175 / 1709\n",
      "176 / 1709\n",
      "177 / 1709\n",
      "178 / 1709\n",
      "179 / 1709\n",
      "180 / 1709\n",
      "181 / 1709\n",
      "182 / 1709\n",
      "183 / 1709\n",
      "184 / 1709\n",
      "185 / 1709\n",
      "186 / 1709\n",
      "187 / 1709\n",
      "188 / 1709\n",
      "189 / 1709\n",
      "190 / 1709\n",
      "191 / 1709\n",
      "192 / 1709\n",
      "193 / 1709\n",
      "194 / 1709\n",
      "195 / 1709\n",
      "196 / 1709\n",
      "197 / 1709\n",
      "198 / 1709\n",
      "199 / 1709\n",
      "200 / 1709\n",
      "201 / 1709\n",
      "202 / 1709\n",
      "203 / 1709\n",
      "204 / 1709\n",
      "205 / 1709\n",
      "206 / 1709\n",
      "207 / 1709\n",
      "208 / 1709\n",
      "209 / 1709\n",
      "210 / 1709\n",
      "211 / 1709\n",
      "212 / 1709\n",
      "213 / 1709\n",
      "214 / 1709\n",
      "215 / 1709\n",
      "216 / 1709\n",
      "217 / 1709\n",
      "218 / 1709\n",
      "219 / 1709\n",
      "220 / 1709\n",
      "221 / 1709\n",
      "222 / 1709\n",
      "223 / 1709\n",
      "224 / 1709\n",
      "225 / 1709\n",
      "226 / 1709\n",
      "227 / 1709\n",
      "228 / 1709\n",
      "229 / 1709\n",
      "230 / 1709\n",
      "231 / 1709\n",
      "232 / 1709\n",
      "233 / 1709\n",
      "234 / 1709\n",
      "235 / 1709\n",
      "236 / 1709\n",
      "237 / 1709\n",
      "238 / 1709\n",
      "239 / 1709\n",
      "240 / 1709\n",
      "241 / 1709\n",
      "242 / 1709\n",
      "243 / 1709\n",
      "244 / 1709\n",
      "245 / 1709\n",
      "246 / 1709\n",
      "247 / 1709\n",
      "248 / 1709\n",
      "249 / 1709\n",
      "250 / 1709\n",
      "251 / 1709\n",
      "252 / 1709\n",
      "253 / 1709\n",
      "254 / 1709\n",
      "255 / 1709\n",
      "256 / 1709\n",
      "257 / 1709\n",
      "258 / 1709\n",
      "259 / 1709\n",
      "260 / 1709\n",
      "261 / 1709\n",
      "262 / 1709\n",
      "263 / 1709\n",
      "264 / 1709\n",
      "265 / 1709\n",
      "266 / 1709\n",
      "267 / 1709\n",
      "268 / 1709\n",
      "269 / 1709\n",
      "270 / 1709\n",
      "271 / 1709\n",
      "272 / 1709\n",
      "273 / 1709\n",
      "274 / 1709\n",
      "275 / 1709\n",
      "276 / 1709\n",
      "277 / 1709\n",
      "278 / 1709\n",
      "279 / 1709\n",
      "280 / 1709\n",
      "281 / 1709\n",
      "282 / 1709\n",
      "283 / 1709\n",
      "284 / 1709\n",
      "285 / 1709\n",
      "286 / 1709\n",
      "287 / 1709\n",
      "288 / 1709\n",
      "289 / 1709\n",
      "290 / 1709\n",
      "291 / 1709\n",
      "292 / 1709\n",
      "293 / 1709\n",
      "294 / 1709\n",
      "295 / 1709\n",
      "296 / 1709\n",
      "297 / 1709\n",
      "298 / 1709\n",
      "299 / 1709\n",
      "300 / 1709\n",
      "301 / 1709\n",
      "302 / 1709\n",
      "303 / 1709\n",
      "304 / 1709\n",
      "305 / 1709\n",
      "306 / 1709\n",
      "307 / 1709\n",
      "308 / 1709\n",
      "309 / 1709\n",
      "310 / 1709\n",
      "311 / 1709\n",
      "312 / 1709\n",
      "313 / 1709\n",
      "314 / 1709\n",
      "315 / 1709\n",
      "316 / 1709\n",
      "317 / 1709\n",
      "318 / 1709\n",
      "319 / 1709\n",
      "320 / 1709\n",
      "321 / 1709\n",
      "322 / 1709\n",
      "323 / 1709\n",
      "324 / 1709\n",
      "325 / 1709\n",
      "326 / 1709\n",
      "327 / 1709\n",
      "328 / 1709\n",
      "329 / 1709\n",
      "330 / 1709\n",
      "331 / 1709\n",
      "332 / 1709\n",
      "333 / 1709\n",
      "334 / 1709\n",
      "335 / 1709\n",
      "336 / 1709\n",
      "337 / 1709\n",
      "338 / 1709\n",
      "339 / 1709\n",
      "340 / 1709\n",
      "341 / 1709\n",
      "342 / 1709\n",
      "343 / 1709\n",
      "344 / 1709\n",
      "345 / 1709\n",
      "346 / 1709\n",
      "347 / 1709\n",
      "348 / 1709\n",
      "349 / 1709\n",
      "350 / 1709\n",
      "351 / 1709\n",
      "352 / 1709\n",
      "353 / 1709\n",
      "354 / 1709\n",
      "355 / 1709\n",
      "356 / 1709\n",
      "357 / 1709\n",
      "358 / 1709\n",
      "359 / 1709\n",
      "360 / 1709\n",
      "361 / 1709\n",
      "362 / 1709\n",
      "363 / 1709\n",
      "364 / 1709\n",
      "365 / 1709\n",
      "366 / 1709\n",
      "367 / 1709\n",
      "368 / 1709\n",
      "369 / 1709\n",
      "370 / 1709\n",
      "371 / 1709\n",
      "372 / 1709\n",
      "373 / 1709\n",
      "374 / 1709\n",
      "375 / 1709\n",
      "376 / 1709\n",
      "377 / 1709\n",
      "378 / 1709\n",
      "379 / 1709\n",
      "380 / 1709\n",
      "381 / 1709\n",
      "382 / 1709\n",
      "383 / 1709\n",
      "384 / 1709\n",
      "385 / 1709\n",
      "386 / 1709\n",
      "387 / 1709\n",
      "388 / 1709\n",
      "389 / 1709\n",
      "390 / 1709\n",
      "391 / 1709\n",
      "392 / 1709\n",
      "393 / 1709\n",
      "394 / 1709\n",
      "395 / 1709\n",
      "396 / 1709\n",
      "397 / 1709\n",
      "398 / 1709\n",
      "399 / 1709\n",
      "400 / 1709\n",
      "401 / 1709\n",
      "402 / 1709\n",
      "403 / 1709\n",
      "404 / 1709\n",
      "405 / 1709\n",
      "406 / 1709\n",
      "407 / 1709\n",
      "408 / 1709\n",
      "409 / 1709\n",
      "410 / 1709\n",
      "411 / 1709\n",
      "412 / 1709\n",
      "413 / 1709\n",
      "414 / 1709\n",
      "415 / 1709\n",
      "416 / 1709\n",
      "417 / 1709\n",
      "418 / 1709\n",
      "419 / 1709\n",
      "420 / 1709\n",
      "421 / 1709\n",
      "422 / 1709\n",
      "423 / 1709\n",
      "424 / 1709\n",
      "425 / 1709\n",
      "426 / 1709\n",
      "427 / 1709\n",
      "428 / 1709\n",
      "429 / 1709\n",
      "430 / 1709\n",
      "431 / 1709\n",
      "432 / 1709\n",
      "433 / 1709\n",
      "434 / 1709\n",
      "435 / 1709\n",
      "436 / 1709\n",
      "437 / 1709\n",
      "438 / 1709\n",
      "439 / 1709\n",
      "440 / 1709\n",
      "441 / 1709\n",
      "442 / 1709\n",
      "443 / 1709\n",
      "444 / 1709\n",
      "445 / 1709\n",
      "446 / 1709\n",
      "447 / 1709\n",
      "448 / 1709\n",
      "449 / 1709\n",
      "450 / 1709\n",
      "451 / 1709\n",
      "452 / 1709\n",
      "453 / 1709\n",
      "454 / 1709\n",
      "455 / 1709\n",
      "456 / 1709\n",
      "457 / 1709\n",
      "458 / 1709\n",
      "459 / 1709\n",
      "460 / 1709\n",
      "461 / 1709\n",
      "462 / 1709\n",
      "463 / 1709\n",
      "464 / 1709\n",
      "465 / 1709\n",
      "466 / 1709\n",
      "467 / 1709\n",
      "468 / 1709\n",
      "469 / 1709\n",
      "470 / 1709\n",
      "471 / 1709\n",
      "472 / 1709\n",
      "473 / 1709\n",
      "474 / 1709\n",
      "475 / 1709\n",
      "476 / 1709\n",
      "477 / 1709\n",
      "478 / 1709\n",
      "479 / 1709\n",
      "480 / 1709\n",
      "481 / 1709\n",
      "482 / 1709\n",
      "483 / 1709\n",
      "484 / 1709\n",
      "485 / 1709\n",
      "486 / 1709\n",
      "487 / 1709\n",
      "488 / 1709\n",
      "489 / 1709\n",
      "490 / 1709\n",
      "491 / 1709\n",
      "492 / 1709\n",
      "493 / 1709\n",
      "494 / 1709\n",
      "495 / 1709\n",
      "496 / 1709\n",
      "497 / 1709\n",
      "498 / 1709\n",
      "499 / 1709\n",
      "500 / 1709\n",
      "501 / 1709\n",
      "502 / 1709\n",
      "503 / 1709\n",
      "504 / 1709\n",
      "505 / 1709\n",
      "506 / 1709\n",
      "507 / 1709\n",
      "508 / 1709\n",
      "509 / 1709\n",
      "510 / 1709\n",
      "511 / 1709\n",
      "512 / 1709\n",
      "513 / 1709\n",
      "514 / 1709\n",
      "515 / 1709\n",
      "516 / 1709\n",
      "517 / 1709\n",
      "518 / 1709\n",
      "519 / 1709\n",
      "520 / 1709\n",
      "521 / 1709\n",
      "522 / 1709\n",
      "523 / 1709\n",
      "524 / 1709\n",
      "525 / 1709\n",
      "526 / 1709\n",
      "527 / 1709\n",
      "528 / 1709\n",
      "529 / 1709\n",
      "530 / 1709\n",
      "531 / 1709\n",
      "532 / 1709\n",
      "533 / 1709\n",
      "534 / 1709\n",
      "535 / 1709\n",
      "536 / 1709\n",
      "537 / 1709\n",
      "538 / 1709\n",
      "539 / 1709\n",
      "540 / 1709\n",
      "541 / 1709\n",
      "542 / 1709\n",
      "543 / 1709\n",
      "544 / 1709\n",
      "545 / 1709\n",
      "546 / 1709\n",
      "547 / 1709\n",
      "548 / 1709\n",
      "549 / 1709\n",
      "550 / 1709\n",
      "551 / 1709\n",
      "552 / 1709\n",
      "553 / 1709\n",
      "554 / 1709\n",
      "555 / 1709\n",
      "556 / 1709\n",
      "557 / 1709\n",
      "558 / 1709\n",
      "559 / 1709\n",
      "560 / 1709\n",
      "561 / 1709\n",
      "562 / 1709\n",
      "563 / 1709\n",
      "564 / 1709\n",
      "565 / 1709\n",
      "566 / 1709\n",
      "567 / 1709\n",
      "568 / 1709\n",
      "569 / 1709\n",
      "570 / 1709\n",
      "571 / 1709\n",
      "572 / 1709\n",
      "573 / 1709\n",
      "574 / 1709\n",
      "575 / 1709\n",
      "576 / 1709\n",
      "577 / 1709\n",
      "578 / 1709\n",
      "579 / 1709\n",
      "580 / 1709\n",
      "581 / 1709\n",
      "582 / 1709\n",
      "583 / 1709\n",
      "584 / 1709\n",
      "585 / 1709\n",
      "586 / 1709\n",
      "587 / 1709\n",
      "588 / 1709\n",
      "589 / 1709\n",
      "590 / 1709\n",
      "591 / 1709\n",
      "592 / 1709\n",
      "593 / 1709\n",
      "594 / 1709\n",
      "595 / 1709\n",
      "596 / 1709\n",
      "597 / 1709\n",
      "598 / 1709\n",
      "599 / 1709\n",
      "600 / 1709\n",
      "601 / 1709\n",
      "602 / 1709\n",
      "603 / 1709\n",
      "604 / 1709\n",
      "605 / 1709\n",
      "606 / 1709\n",
      "607 / 1709\n",
      "608 / 1709\n",
      "609 / 1709\n",
      "610 / 1709\n",
      "611 / 1709\n",
      "612 / 1709\n",
      "613 / 1709\n",
      "614 / 1709\n",
      "615 / 1709\n",
      "616 / 1709\n",
      "617 / 1709\n",
      "618 / 1709\n",
      "619 / 1709\n",
      "620 / 1709\n",
      "621 / 1709\n",
      "622 / 1709\n",
      "623 / 1709\n",
      "624 / 1709\n",
      "625 / 1709\n",
      "626 / 1709\n",
      "627 / 1709\n",
      "628 / 1709\n",
      "629 / 1709\n",
      "630 / 1709\n",
      "631 / 1709\n",
      "632 / 1709\n",
      "633 / 1709\n",
      "634 / 1709\n",
      "635 / 1709\n",
      "636 / 1709\n",
      "637 / 1709\n",
      "638 / 1709\n",
      "639 / 1709\n",
      "640 / 1709\n",
      "641 / 1709\n",
      "642 / 1709\n",
      "643 / 1709\n",
      "644 / 1709\n",
      "645 / 1709\n",
      "646 / 1709\n",
      "647 / 1709\n",
      "648 / 1709\n",
      "649 / 1709\n",
      "650 / 1709\n",
      "651 / 1709\n",
      "652 / 1709\n",
      "653 / 1709\n",
      "654 / 1709\n",
      "655 / 1709\n",
      "656 / 1709\n",
      "657 / 1709\n",
      "658 / 1709\n",
      "659 / 1709\n",
      "660 / 1709\n",
      "661 / 1709\n",
      "662 / 1709\n",
      "663 / 1709\n",
      "664 / 1709\n",
      "665 / 1709\n",
      "666 / 1709\n",
      "667 / 1709\n",
      "668 / 1709\n",
      "669 / 1709\n",
      "670 / 1709\n",
      "671 / 1709\n",
      "672 / 1709\n",
      "673 / 1709\n",
      "674 / 1709\n",
      "675 / 1709\n",
      "676 / 1709\n",
      "677 / 1709\n",
      "678 / 1709\n",
      "679 / 1709\n",
      "680 / 1709\n",
      "681 / 1709\n",
      "682 / 1709\n",
      "683 / 1709\n",
      "684 / 1709\n",
      "685 / 1709\n",
      "686 / 1709\n",
      "687 / 1709\n",
      "688 / 1709\n",
      "689 / 1709\n",
      "690 / 1709\n",
      "691 / 1709\n",
      "692 / 1709\n",
      "693 / 1709\n",
      "694 / 1709\n",
      "695 / 1709\n",
      "696 / 1709\n",
      "697 / 1709\n",
      "698 / 1709\n",
      "699 / 1709\n",
      "700 / 1709\n",
      "701 / 1709\n",
      "702 / 1709\n",
      "703 / 1709\n",
      "704 / 1709\n",
      "705 / 1709\n",
      "706 / 1709\n",
      "707 / 1709\n",
      "708 / 1709\n",
      "709 / 1709\n",
      "710 / 1709\n",
      "711 / 1709\n",
      "712 / 1709\n",
      "713 / 1709\n",
      "714 / 1709\n",
      "715 / 1709\n",
      "716 / 1709\n",
      "717 / 1709\n",
      "718 / 1709\n",
      "719 / 1709\n",
      "720 / 1709\n",
      "721 / 1709\n",
      "722 / 1709\n",
      "723 / 1709\n",
      "724 / 1709\n",
      "725 / 1709\n",
      "726 / 1709\n",
      "727 / 1709\n",
      "728 / 1709\n",
      "729 / 1709\n",
      "730 / 1709\n",
      "731 / 1709\n",
      "732 / 1709\n",
      "733 / 1709\n",
      "734 / 1709\n",
      "735 / 1709\n",
      "736 / 1709\n",
      "737 / 1709\n",
      "738 / 1709\n",
      "739 / 1709\n",
      "740 / 1709\n",
      "741 / 1709\n",
      "742 / 1709\n",
      "743 / 1709\n",
      "744 / 1709\n",
      "745 / 1709\n",
      "746 / 1709\n",
      "747 / 1709\n",
      "748 / 1709\n",
      "749 / 1709\n",
      "750 / 1709\n",
      "751 / 1709\n",
      "752 / 1709\n",
      "753 / 1709\n",
      "754 / 1709\n",
      "755 / 1709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756 / 1709\n",
      "757 / 1709\n",
      "758 / 1709\n",
      "759 / 1709\n",
      "760 / 1709\n",
      "761 / 1709\n",
      "762 / 1709\n",
      "763 / 1709\n",
      "764 / 1709\n",
      "765 / 1709\n",
      "766 / 1709\n",
      "767 / 1709\n",
      "768 / 1709\n",
      "769 / 1709\n",
      "770 / 1709\n",
      "771 / 1709\n",
      "772 / 1709\n",
      "773 / 1709\n",
      "774 / 1709\n",
      "775 / 1709\n",
      "776 / 1709\n",
      "777 / 1709\n",
      "778 / 1709\n",
      "779 / 1709\n",
      "780 / 1709\n",
      "781 / 1709\n",
      "782 / 1709\n",
      "783 / 1709\n",
      "784 / 1709\n",
      "785 / 1709\n",
      "786 / 1709\n",
      "787 / 1709\n",
      "788 / 1709\n",
      "789 / 1709\n",
      "790 / 1709\n",
      "791 / 1709\n",
      "792 / 1709\n",
      "793 / 1709\n",
      "794 / 1709\n",
      "795 / 1709\n",
      "796 / 1709\n",
      "797 / 1709\n",
      "798 / 1709\n",
      "799 / 1709\n",
      "800 / 1709\n",
      "801 / 1709\n",
      "802 / 1709\n",
      "803 / 1709\n",
      "804 / 1709\n",
      "805 / 1709\n",
      "806 / 1709\n",
      "807 / 1709\n",
      "808 / 1709\n",
      "809 / 1709\n",
      "810 / 1709\n",
      "811 / 1709\n",
      "812 / 1709\n",
      "813 / 1709\n",
      "814 / 1709\n",
      "815 / 1709\n",
      "816 / 1709\n",
      "817 / 1709\n",
      "818 / 1709\n",
      "819 / 1709\n",
      "820 / 1709\n",
      "821 / 1709\n",
      "822 / 1709\n",
      "823 / 1709\n",
      "824 / 1709\n",
      "825 / 1709\n",
      "826 / 1709\n",
      "827 / 1709\n",
      "828 / 1709\n",
      "829 / 1709\n",
      "830 / 1709\n",
      "831 / 1709\n",
      "832 / 1709\n",
      "833 / 1709\n",
      "834 / 1709\n",
      "835 / 1709\n",
      "836 / 1709\n",
      "837 / 1709\n",
      "838 / 1709\n",
      "839 / 1709\n",
      "840 / 1709\n",
      "841 / 1709\n",
      "842 / 1709\n",
      "843 / 1709\n",
      "844 / 1709\n",
      "845 / 1709\n",
      "846 / 1709\n",
      "847 / 1709\n",
      "848 / 1709\n",
      "849 / 1709\n",
      "850 / 1709\n",
      "851 / 1709\n",
      "852 / 1709\n",
      "853 / 1709\n",
      "854 / 1709\n",
      "855 / 1709\n",
      "856 / 1709\n",
      "857 / 1709\n",
      "858 / 1709\n",
      "859 / 1709\n",
      "860 / 1709\n",
      "861 / 1709\n",
      "862 / 1709\n",
      "863 / 1709\n",
      "864 / 1709\n",
      "865 / 1709\n",
      "866 / 1709\n",
      "867 / 1709\n",
      "868 / 1709\n",
      "869 / 1709\n",
      "870 / 1709\n",
      "871 / 1709\n",
      "872 / 1709\n",
      "873 / 1709\n",
      "874 / 1709\n",
      "875 / 1709\n",
      "876 / 1709\n",
      "877 / 1709\n",
      "878 / 1709\n",
      "879 / 1709\n",
      "880 / 1709\n",
      "881 / 1709\n",
      "882 / 1709\n",
      "883 / 1709\n",
      "884 / 1709\n",
      "885 / 1709\n",
      "886 / 1709\n",
      "887 / 1709\n",
      "888 / 1709\n",
      "889 / 1709\n",
      "890 / 1709\n",
      "891 / 1709\n",
      "892 / 1709\n",
      "893 / 1709\n",
      "894 / 1709\n",
      "895 / 1709\n",
      "896 / 1709\n",
      "897 / 1709\n",
      "898 / 1709\n",
      "899 / 1709\n",
      "900 / 1709\n",
      "901 / 1709\n",
      "902 / 1709\n",
      "903 / 1709\n",
      "904 / 1709\n",
      "905 / 1709\n",
      "906 / 1709\n",
      "907 / 1709\n",
      "908 / 1709\n",
      "909 / 1709\n",
      "910 / 1709\n",
      "911 / 1709\n",
      "912 / 1709\n",
      "913 / 1709\n",
      "914 / 1709\n",
      "915 / 1709\n",
      "916 / 1709\n",
      "917 / 1709\n",
      "918 / 1709\n",
      "919 / 1709\n",
      "920 / 1709\n",
      "921 / 1709\n",
      "922 / 1709\n",
      "923 / 1709\n",
      "924 / 1709\n",
      "925 / 1709\n",
      "926 / 1709\n",
      "927 / 1709\n",
      "928 / 1709\n",
      "929 / 1709\n",
      "930 / 1709\n",
      "931 / 1709\n",
      "932 / 1709\n",
      "933 / 1709\n",
      "934 / 1709\n",
      "935 / 1709\n",
      "936 / 1709\n",
      "937 / 1709\n",
      "938 / 1709\n",
      "939 / 1709\n",
      "940 / 1709\n",
      "941 / 1709\n",
      "942 / 1709\n",
      "943 / 1709\n",
      "944 / 1709\n",
      "945 / 1709\n",
      "946 / 1709\n",
      "947 / 1709\n",
      "948 / 1709\n",
      "949 / 1709\n",
      "950 / 1709\n",
      "951 / 1709\n",
      "952 / 1709\n",
      "953 / 1709\n",
      "954 / 1709\n",
      "955 / 1709\n",
      "956 / 1709\n",
      "957 / 1709\n",
      "958 / 1709\n",
      "959 / 1709\n",
      "960 / 1709\n",
      "961 / 1709\n",
      "962 / 1709\n",
      "963 / 1709\n",
      "964 / 1709\n",
      "965 / 1709\n",
      "966 / 1709\n",
      "967 / 1709\n",
      "968 / 1709\n",
      "969 / 1709\n",
      "970 / 1709\n",
      "971 / 1709\n",
      "972 / 1709\n",
      "973 / 1709\n",
      "974 / 1709\n",
      "975 / 1709\n",
      "976 / 1709\n",
      "977 / 1709\n",
      "978 / 1709\n",
      "979 / 1709\n",
      "980 / 1709\n",
      "981 / 1709\n",
      "982 / 1709\n",
      "983 / 1709\n",
      "984 / 1709\n",
      "985 / 1709\n",
      "986 / 1709\n",
      "987 / 1709\n",
      "988 / 1709\n",
      "989 / 1709\n",
      "990 / 1709\n",
      "991 / 1709\n",
      "992 / 1709\n",
      "993 / 1709\n",
      "994 / 1709\n",
      "995 / 1709\n",
      "996 / 1709\n",
      "997 / 1709\n",
      "998 / 1709\n",
      "999 / 1709\n",
      "1000 / 1709\n",
      "1001 / 1709\n",
      "1002 / 1709\n",
      "1003 / 1709\n",
      "1004 / 1709\n",
      "1005 / 1709\n",
      "1006 / 1709\n",
      "1007 / 1709\n",
      "1008 / 1709\n",
      "1009 / 1709\n",
      "1010 / 1709\n",
      "1011 / 1709\n",
      "1012 / 1709\n",
      "1013 / 1709\n",
      "1014 / 1709\n",
      "1015 / 1709\n",
      "1016 / 1709\n",
      "1017 / 1709\n",
      "1018 / 1709\n",
      "1019 / 1709\n",
      "1020 / 1709\n",
      "1021 / 1709\n",
      "1022 / 1709\n",
      "1023 / 1709\n",
      "1024 / 1709\n",
      "1025 / 1709\n",
      "1026 / 1709\n",
      "1027 / 1709\n",
      "1028 / 1709\n",
      "1029 / 1709\n",
      "1030 / 1709\n",
      "1031 / 1709\n",
      "1032 / 1709\n",
      "1033 / 1709\n",
      "1034 / 1709\n",
      "1035 / 1709\n",
      "1036 / 1709\n",
      "1037 / 1709\n",
      "1038 / 1709\n",
      "1039 / 1709\n",
      "1040 / 1709\n",
      "1041 / 1709\n",
      "1042 / 1709\n",
      "1043 / 1709\n",
      "1044 / 1709\n",
      "1045 / 1709\n",
      "1046 / 1709\n",
      "1047 / 1709\n",
      "1048 / 1709\n",
      "1049 / 1709\n",
      "1050 / 1709\n",
      "1051 / 1709\n",
      "1052 / 1709\n",
      "1053 / 1709\n",
      "1054 / 1709\n",
      "1055 / 1709\n",
      "1056 / 1709\n",
      "1057 / 1709\n",
      "1058 / 1709\n",
      "1059 / 1709\n",
      "1060 / 1709\n",
      "1061 / 1709\n",
      "1062 / 1709\n",
      "1063 / 1709\n",
      "1064 / 1709\n",
      "1065 / 1709\n",
      "1066 / 1709\n",
      "1067 / 1709\n",
      "1068 / 1709\n",
      "1069 / 1709\n",
      "1070 / 1709\n",
      "1071 / 1709\n",
      "1072 / 1709\n",
      "1073 / 1709\n",
      "1074 / 1709\n",
      "1075 / 1709\n",
      "1076 / 1709\n",
      "1077 / 1709\n",
      "1078 / 1709\n",
      "1079 / 1709\n",
      "1080 / 1709\n",
      "1081 / 1709\n",
      "1082 / 1709\n",
      "1083 / 1709\n",
      "1084 / 1709\n",
      "1085 / 1709\n",
      "1086 / 1709\n",
      "1087 / 1709\n",
      "1088 / 1709\n",
      "1089 / 1709\n",
      "1090 / 1709\n",
      "1091 / 1709\n",
      "1092 / 1709\n",
      "1093 / 1709\n",
      "1094 / 1709\n",
      "1095 / 1709\n",
      "1096 / 1709\n",
      "1097 / 1709\n",
      "1098 / 1709\n",
      "1099 / 1709\n",
      "1100 / 1709\n",
      "1101 / 1709\n",
      "1102 / 1709\n",
      "1103 / 1709\n",
      "1104 / 1709\n",
      "1105 / 1709\n",
      "1106 / 1709\n",
      "1107 / 1709\n",
      "1108 / 1709\n",
      "1109 / 1709\n",
      "1110 / 1709\n",
      "1111 / 1709\n",
      "1112 / 1709\n",
      "1113 / 1709\n",
      "1114 / 1709\n",
      "1115 / 1709\n",
      "1116 / 1709\n",
      "1117 / 1709\n",
      "1118 / 1709\n",
      "1119 / 1709\n",
      "1120 / 1709\n",
      "1121 / 1709\n",
      "1122 / 1709\n",
      "1123 / 1709\n",
      "1124 / 1709\n",
      "1125 / 1709\n",
      "1126 / 1709\n",
      "1127 / 1709\n",
      "1128 / 1709\n",
      "1129 / 1709\n",
      "1130 / 1709\n",
      "1131 / 1709\n",
      "1132 / 1709\n",
      "1133 / 1709\n",
      "1134 / 1709\n",
      "1135 / 1709\n",
      "1136 / 1709\n",
      "1137 / 1709\n",
      "1138 / 1709\n",
      "1139 / 1709\n",
      "1140 / 1709\n",
      "1141 / 1709\n",
      "1142 / 1709\n",
      "1143 / 1709\n",
      "1144 / 1709\n",
      "1145 / 1709\n",
      "1146 / 1709\n",
      "1147 / 1709\n",
      "1148 / 1709\n",
      "1149 / 1709\n",
      "1150 / 1709\n",
      "1151 / 1709\n",
      "1152 / 1709\n",
      "1153 / 1709\n",
      "1154 / 1709\n",
      "1155 / 1709\n",
      "1156 / 1709\n",
      "1157 / 1709\n",
      "1158 / 1709\n",
      "1159 / 1709\n",
      "1160 / 1709\n",
      "1161 / 1709\n",
      "1162 / 1709\n",
      "1163 / 1709\n",
      "1164 / 1709\n",
      "1165 / 1709\n",
      "1166 / 1709\n",
      "1167 / 1709\n",
      "1168 / 1709\n",
      "1169 / 1709\n",
      "1170 / 1709\n",
      "1171 / 1709\n",
      "1172 / 1709\n",
      "1173 / 1709\n",
      "1174 / 1709\n",
      "1175 / 1709\n",
      "1176 / 1709\n",
      "1177 / 1709\n",
      "1178 / 1709\n",
      "1179 / 1709\n",
      "1180 / 1709\n",
      "1181 / 1709\n",
      "1182 / 1709\n",
      "1183 / 1709\n",
      "1184 / 1709\n",
      "1185 / 1709\n",
      "1186 / 1709\n",
      "1187 / 1709\n",
      "1188 / 1709\n",
      "1189 / 1709\n",
      "1190 / 1709\n",
      "1191 / 1709\n",
      "1192 / 1709\n",
      "1193 / 1709\n",
      "1194 / 1709\n",
      "1195 / 1709\n",
      "1196 / 1709\n",
      "1197 / 1709\n",
      "1198 / 1709\n",
      "1199 / 1709\n",
      "1200 / 1709\n",
      "1201 / 1709\n",
      "1202 / 1709\n",
      "1203 / 1709\n",
      "1204 / 1709\n",
      "1205 / 1709\n",
      "1206 / 1709\n",
      "1207 / 1709\n",
      "1208 / 1709\n",
      "1209 / 1709\n",
      "1210 / 1709\n",
      "1211 / 1709\n",
      "1212 / 1709\n",
      "1213 / 1709\n",
      "1214 / 1709\n",
      "1215 / 1709\n",
      "1216 / 1709\n",
      "1217 / 1709\n",
      "1218 / 1709\n",
      "1219 / 1709\n",
      "1220 / 1709\n",
      "1221 / 1709\n",
      "1222 / 1709\n",
      "1223 / 1709\n",
      "1224 / 1709\n",
      "1225 / 1709\n",
      "1226 / 1709\n",
      "1227 / 1709\n",
      "1228 / 1709\n",
      "1229 / 1709\n",
      "1230 / 1709\n",
      "1231 / 1709\n",
      "1232 / 1709\n",
      "1233 / 1709\n",
      "1234 / 1709\n",
      "1235 / 1709\n",
      "1236 / 1709\n",
      "1237 / 1709\n",
      "1238 / 1709\n",
      "1239 / 1709\n",
      "1240 / 1709\n",
      "1241 / 1709\n",
      "1242 / 1709\n",
      "1243 / 1709\n",
      "1244 / 1709\n",
      "1245 / 1709\n",
      "1246 / 1709\n",
      "1247 / 1709\n",
      "1248 / 1709\n",
      "1249 / 1709\n",
      "1250 / 1709\n",
      "1251 / 1709\n",
      "1252 / 1709\n",
      "1253 / 1709\n",
      "1254 / 1709\n",
      "1255 / 1709\n",
      "1256 / 1709\n",
      "1257 / 1709\n",
      "1258 / 1709\n",
      "1259 / 1709\n",
      "1260 / 1709\n",
      "1261 / 1709\n",
      "1262 / 1709\n",
      "1263 / 1709\n",
      "1264 / 1709\n",
      "1265 / 1709\n",
      "1266 / 1709\n",
      "1267 / 1709\n",
      "1268 / 1709\n",
      "1269 / 1709\n",
      "1270 / 1709\n",
      "1271 / 1709\n",
      "1272 / 1709\n",
      "1273 / 1709\n",
      "1274 / 1709\n",
      "1275 / 1709\n",
      "1276 / 1709\n",
      "1277 / 1709\n",
      "1278 / 1709\n",
      "1279 / 1709\n",
      "1280 / 1709\n",
      "1281 / 1709\n",
      "1282 / 1709\n",
      "1283 / 1709\n",
      "1284 / 1709\n",
      "1285 / 1709\n",
      "1286 / 1709\n",
      "1287 / 1709\n",
      "1288 / 1709\n",
      "1289 / 1709\n",
      "1290 / 1709\n",
      "1291 / 1709\n",
      "1292 / 1709\n",
      "1293 / 1709\n",
      "1294 / 1709\n",
      "1295 / 1709\n",
      "1296 / 1709\n",
      "1297 / 1709\n",
      "1298 / 1709\n",
      "1299 / 1709\n",
      "1300 / 1709\n",
      "1301 / 1709\n",
      "1302 / 1709\n",
      "1303 / 1709\n",
      "1304 / 1709\n",
      "1305 / 1709\n",
      "1306 / 1709\n",
      "1307 / 1709\n",
      "1308 / 1709\n",
      "1309 / 1709\n",
      "1310 / 1709\n",
      "1311 / 1709\n",
      "1312 / 1709\n",
      "1313 / 1709\n",
      "1314 / 1709\n",
      "1315 / 1709\n",
      "1316 / 1709\n",
      "1317 / 1709\n",
      "1318 / 1709\n",
      "1319 / 1709\n",
      "1320 / 1709\n",
      "1321 / 1709\n",
      "1322 / 1709\n",
      "1323 / 1709\n",
      "1324 / 1709\n",
      "1325 / 1709\n",
      "1326 / 1709\n",
      "1327 / 1709\n",
      "1328 / 1709\n",
      "1329 / 1709\n",
      "1330 / 1709\n",
      "1331 / 1709\n",
      "1332 / 1709\n",
      "1333 / 1709\n",
      "1334 / 1709\n",
      "1335 / 1709\n",
      "1336 / 1709\n",
      "1337 / 1709\n",
      "1338 / 1709\n",
      "1339 / 1709\n",
      "1340 / 1709\n",
      "1341 / 1709\n",
      "1342 / 1709\n",
      "1343 / 1709\n",
      "1344 / 1709\n",
      "1345 / 1709\n",
      "1346 / 1709\n",
      "1347 / 1709\n",
      "1348 / 1709\n",
      "1349 / 1709\n",
      "1350 / 1709\n",
      "1351 / 1709\n",
      "1352 / 1709\n",
      "1353 / 1709\n",
      "1354 / 1709\n",
      "1355 / 1709\n",
      "1356 / 1709\n",
      "1357 / 1709\n",
      "1358 / 1709\n",
      "1359 / 1709\n",
      "1360 / 1709\n",
      "1361 / 1709\n",
      "1362 / 1709\n",
      "1363 / 1709\n",
      "1364 / 1709\n",
      "1365 / 1709\n",
      "1366 / 1709\n",
      "1367 / 1709\n",
      "1368 / 1709\n",
      "1369 / 1709\n",
      "1370 / 1709\n",
      "1371 / 1709\n",
      "1372 / 1709\n",
      "1373 / 1709\n",
      "1374 / 1709\n",
      "1375 / 1709\n",
      "1376 / 1709\n",
      "1377 / 1709\n",
      "1378 / 1709\n",
      "1379 / 1709\n",
      "1380 / 1709\n",
      "1381 / 1709\n",
      "1382 / 1709\n",
      "1383 / 1709\n",
      "1384 / 1709\n",
      "1385 / 1709\n",
      "1386 / 1709\n",
      "1387 / 1709\n",
      "1388 / 1709\n",
      "1389 / 1709\n",
      "1390 / 1709\n",
      "1391 / 1709\n",
      "1392 / 1709\n",
      "1393 / 1709\n",
      "1394 / 1709\n",
      "1395 / 1709\n",
      "1396 / 1709\n",
      "1397 / 1709\n",
      "1398 / 1709\n",
      "1399 / 1709\n",
      "1400 / 1709\n",
      "1401 / 1709\n",
      "1402 / 1709\n",
      "1403 / 1709\n",
      "1404 / 1709\n",
      "1405 / 1709\n",
      "1406 / 1709\n",
      "1407 / 1709\n",
      "1408 / 1709\n",
      "1409 / 1709\n",
      "1410 / 1709\n",
      "1411 / 1709\n",
      "1412 / 1709\n",
      "1413 / 1709\n",
      "1414 / 1709\n",
      "1415 / 1709\n",
      "1416 / 1709\n",
      "1417 / 1709\n",
      "1418 / 1709\n",
      "1419 / 1709\n",
      "1420 / 1709\n",
      "1421 / 1709\n",
      "1422 / 1709\n",
      "1423 / 1709\n",
      "1424 / 1709\n",
      "1425 / 1709\n",
      "1426 / 1709\n",
      "1427 / 1709\n",
      "1428 / 1709\n",
      "1429 / 1709\n",
      "1430 / 1709\n",
      "1431 / 1709\n",
      "1432 / 1709\n",
      "1433 / 1709\n",
      "1434 / 1709\n",
      "1435 / 1709\n",
      "1436 / 1709\n",
      "1437 / 1709\n",
      "1438 / 1709\n",
      "1439 / 1709\n",
      "1440 / 1709\n",
      "1441 / 1709\n",
      "1442 / 1709\n",
      "1443 / 1709\n",
      "1444 / 1709\n",
      "1445 / 1709\n",
      "1446 / 1709\n",
      "1447 / 1709\n",
      "1448 / 1709\n",
      "1449 / 1709\n",
      "1450 / 1709\n",
      "1451 / 1709\n",
      "1452 / 1709\n",
      "1453 / 1709\n",
      "1454 / 1709\n",
      "1455 / 1709\n",
      "1456 / 1709\n",
      "1457 / 1709\n",
      "1458 / 1709\n",
      "1459 / 1709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460 / 1709\n",
      "1461 / 1709\n",
      "1462 / 1709\n",
      "1463 / 1709\n",
      "1464 / 1709\n",
      "1465 / 1709\n",
      "1466 / 1709\n",
      "1467 / 1709\n",
      "1468 / 1709\n",
      "1469 / 1709\n",
      "1470 / 1709\n",
      "1471 / 1709\n",
      "1472 / 1709\n",
      "1473 / 1709\n",
      "1474 / 1709\n",
      "1475 / 1709\n",
      "1476 / 1709\n",
      "1477 / 1709\n",
      "1478 / 1709\n",
      "1479 / 1709\n",
      "1480 / 1709\n",
      "1481 / 1709\n",
      "1482 / 1709\n",
      "1483 / 1709\n",
      "1484 / 1709\n",
      "1485 / 1709\n",
      "1486 / 1709\n",
      "1487 / 1709\n",
      "1488 / 1709\n",
      "1489 / 1709\n",
      "1490 / 1709\n",
      "1491 / 1709\n",
      "1492 / 1709\n",
      "1493 / 1709\n",
      "1494 / 1709\n",
      "1495 / 1709\n",
      "1496 / 1709\n",
      "1497 / 1709\n",
      "1498 / 1709\n",
      "1499 / 1709\n",
      "1500 / 1709\n",
      "1501 / 1709\n",
      "1502 / 1709\n",
      "1503 / 1709\n",
      "1504 / 1709\n",
      "1505 / 1709\n",
      "1506 / 1709\n",
      "1507 / 1709\n",
      "1508 / 1709\n",
      "1509 / 1709\n",
      "1510 / 1709\n",
      "1511 / 1709\n",
      "1512 / 1709\n",
      "1513 / 1709\n",
      "1514 / 1709\n",
      "1515 / 1709\n",
      "1516 / 1709\n",
      "1517 / 1709\n",
      "1518 / 1709\n",
      "1519 / 1709\n",
      "1520 / 1709\n",
      "1521 / 1709\n",
      "1522 / 1709\n",
      "1523 / 1709\n",
      "1524 / 1709\n",
      "1525 / 1709\n",
      "1526 / 1709\n",
      "1527 / 1709\n",
      "1528 / 1709\n",
      "1529 / 1709\n",
      "1530 / 1709\n",
      "1531 / 1709\n",
      "1532 / 1709\n",
      "1533 / 1709\n",
      "1534 / 1709\n",
      "1535 / 1709\n",
      "1536 / 1709\n",
      "1537 / 1709\n",
      "1538 / 1709\n",
      "1539 / 1709\n",
      "1540 / 1709\n",
      "1541 / 1709\n",
      "1542 / 1709\n",
      "1543 / 1709\n",
      "1544 / 1709\n",
      "1545 / 1709\n",
      "1546 / 1709\n",
      "1547 / 1709\n",
      "1548 / 1709\n",
      "1549 / 1709\n",
      "1550 / 1709\n",
      "1551 / 1709\n",
      "1552 / 1709\n",
      "1553 / 1709\n",
      "1554 / 1709\n",
      "1555 / 1709\n",
      "1556 / 1709\n",
      "1557 / 1709\n",
      "1558 / 1709\n",
      "1559 / 1709\n",
      "1560 / 1709\n",
      "1561 / 1709\n",
      "1562 / 1709\n",
      "1563 / 1709\n",
      "1564 / 1709\n",
      "1565 / 1709\n",
      "1566 / 1709\n",
      "1567 / 1709\n",
      "1568 / 1709\n",
      "1569 / 1709\n",
      "1570 / 1709\n",
      "1571 / 1709\n",
      "1572 / 1709\n",
      "1573 / 1709\n",
      "1574 / 1709\n",
      "1575 / 1709\n",
      "1576 / 1709\n",
      "1577 / 1709\n",
      "1578 / 1709\n",
      "1579 / 1709\n",
      "1580 / 1709\n",
      "1581 / 1709\n",
      "1582 / 1709\n",
      "1583 / 1709\n",
      "1584 / 1709\n",
      "1585 / 1709\n",
      "1586 / 1709\n",
      "1587 / 1709\n",
      "1588 / 1709\n",
      "1589 / 1709\n",
      "1590 / 1709\n",
      "1591 / 1709\n",
      "1592 / 1709\n",
      "1593 / 1709\n",
      "1594 / 1709\n",
      "1595 / 1709\n",
      "1596 / 1709\n",
      "1597 / 1709\n",
      "1598 / 1709\n",
      "1599 / 1709\n",
      "1600 / 1709\n",
      "1601 / 1709\n",
      "1602 / 1709\n",
      "1603 / 1709\n",
      "1604 / 1709\n",
      "1605 / 1709\n",
      "1606 / 1709\n",
      "1607 / 1709\n",
      "1608 / 1709\n",
      "1609 / 1709\n",
      "1610 / 1709\n",
      "1611 / 1709\n",
      "1612 / 1709\n",
      "1613 / 1709\n",
      "1614 / 1709\n",
      "1615 / 1709\n",
      "1616 / 1709\n",
      "1617 / 1709\n",
      "1618 / 1709\n",
      "1619 / 1709\n",
      "1620 / 1709\n",
      "1621 / 1709\n",
      "1622 / 1709\n",
      "1623 / 1709\n",
      "1624 / 1709\n",
      "1625 / 1709\n",
      "1626 / 1709\n",
      "1627 / 1709\n",
      "1628 / 1709\n",
      "1629 / 1709\n",
      "1630 / 1709\n",
      "1631 / 1709\n",
      "1632 / 1709\n",
      "1633 / 1709\n",
      "1634 / 1709\n",
      "1635 / 1709\n",
      "1636 / 1709\n",
      "1637 / 1709\n",
      "1638 / 1709\n",
      "1639 / 1709\n",
      "1640 / 1709\n",
      "1641 / 1709\n",
      "1642 / 1709\n",
      "1643 / 1709\n",
      "1644 / 1709\n",
      "1645 / 1709\n",
      "1646 / 1709\n",
      "1647 / 1709\n",
      "1648 / 1709\n",
      "1649 / 1709\n",
      "1650 / 1709\n",
      "1651 / 1709\n",
      "1652 / 1709\n",
      "1653 / 1709\n",
      "1654 / 1709\n",
      "1655 / 1709\n",
      "1656 / 1709\n",
      "1657 / 1709\n",
      "1658 / 1709\n",
      "1659 / 1709\n",
      "1660 / 1709\n",
      "1661 / 1709\n",
      "1662 / 1709\n",
      "1663 / 1709\n",
      "1664 / 1709\n",
      "1665 / 1709\n",
      "1666 / 1709\n",
      "1667 / 1709\n",
      "1668 / 1709\n",
      "1669 / 1709\n",
      "1670 / 1709\n",
      "1671 / 1709\n",
      "1672 / 1709\n",
      "1673 / 1709\n",
      "1674 / 1709\n",
      "1675 / 1709\n",
      "1676 / 1709\n",
      "1677 / 1709\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens, however you requested 4814 tokens (3314 in your prompt; 1500 for the completion). Please reduce your prompt; or completion length.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m / \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(chunks)))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# translate each chunk\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m translated_chunks\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtranslate_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[22], line 7\u001b[0m, in \u001b[0;36mtranslate_chunk\u001b[1;34m(chunk, engine, dest_language)\u001b[0m\n\u001b[0;32m      3\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mTranslate only the text from the following text document into \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdest_language\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     result \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\openai\\api_resources\\completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    217\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    218\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    613\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    614\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    615\u001b[0m         )\n\u001b[0;32m    616\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    617\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 620\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    626\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    627\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    681\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    684\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens, however you requested 4814 tokens (3314 in your prompt; 1500 for the completion). Please reduce your prompt; or completion length."
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"translated_chunks = []\\nfor i, chunk in enumerate(chunks):\\n    print(str(i+1) + \\\" / \\\" + str(len(chunks)))\\n    # translate each chunk\\n    translated_chunks.append(translate_chunk(chunk))\";\n",
       "                var nbb_formatted_code = \"translated_chunks = []\\nfor i, chunk in enumerate(chunks):\\n    print(str(i + 1) + \\\" / \\\" + str(len(chunks)))\\n    # translate each chunk\\n    translated_chunks.append(translate_chunk(chunk))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an empty list to hold the translated chunks.\n",
    "translated_chunks = []\n",
    "# Iterate over each chunk in the list of chunks\n",
    "for i, chunk in enumerate(chunks):\n",
    "    # Print the progress of the loop\n",
    "    print(str(i + 1) + \" / \" + str(len(chunks)))\n",
    "    # Call the translate_chunk function on the current chunk and append the result to the list of translated chunks\n",
    "    translated_chunks.append(translate_chunk(chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d6d6e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# join the chunks together\\nresult = '\\\\n\\\\n'.join(translated_chunks)\";\n",
       "                var nbb_formatted_code = \"# join the chunks together\\nresult = \\\"\\\\n\\\\n\\\".join(translated_chunks)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Join the chunks together\n",
    "result = \"\\n\\n\".join(translated_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "521ef96c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270525"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"open(str_path_output_txt_en, \\\"w\\\", encoding=\\\"utf8\\\").write(result)\";\n",
       "                var nbb_formatted_code = \"open(str_path_output_txt_en, \\\"w\\\", encoding=\\\"utf8\\\").write(result)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Saves the translated text into a file\n",
    "open(str_path_output_txt_en, \"w\", encoding=\"utf8\").write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "43e46fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 116;\n",
       "                var nbb_unformatted_code = \"# Load english file\\nloader_en = TextLoader(str_path_output_txt_en)\";\n",
       "                var nbb_formatted_code = \"# Load english file\\nloader_en = TextLoader(str_path_output_txt_en)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load english file\n",
    "loader_en = TextLoader(str_path_output_txt_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc7b6c5",
   "metadata": {},
   "source": [
    "### Text to vector database "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2254363",
   "metadata": {},
   "source": [
    "#### Split text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e249c2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"# Using PdfReader\\n# We need to split the text that we read into smaller chunks so that during information retreival we don't hit the token size limits\\ntext_splitter = RecursiveCharacterTextSplitter(\\n    separators=\\\"\\\\n\\\",\\n    chunk_size=1000,\\n    chunk_overlap=200,\\n    length_function=len,\\n)\\ntexts = text_splitter.split_text(result)\";\n",
       "                var nbb_formatted_code = \"# Using PdfReader\\n# We need to split the text that we read into smaller chunks so that during information retreival we don't hit the token size limits\\ntext_splitter = RecursiveCharacterTextSplitter(\\n    separators=\\\"\\\\n\\\",\\n    chunk_size=1000,\\n    chunk_overlap=200,\\n    length_function=len,\\n)\\ntexts = text_splitter.split_text(result)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using PdfReader\n",
    "# We need to split the text that we read into smaller chunks so that during information retreival we don't hit the token size limits\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b69e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = text_splitter.split_text(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a68568f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 350 document(s) in your data\n",
      "There are 306013 characters in your document\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 67;\n",
       "                var nbb_unformatted_code = \"print(f\\\"You have {len(texts)} document(s) in your data\\\")\\nprint(f\\\"There are {sum(len(i) for i in texts)} characters in your document\\\")\";\n",
       "                var nbb_formatted_code = \"print(f\\\"You have {len(texts)} document(s) in your data\\\")\\nprint(f\\\"There are {sum(len(i) for i in texts)} characters in your document\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"You have {len(texts)} document(s) in your data\")\n",
    "print(f\"There are {sum(len(i) for i in texts)} characters in your document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e23e42",
   "metadata": {},
   "source": [
    "#### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8b043335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 73;\n",
       "                var nbb_unformatted_code = \"# Create an instance of the OpenAIEmbeddings class\\nembeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\";\n",
       "                var nbb_formatted_code = \"# Create an instance of the OpenAIEmbeddings class\\nembeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an instance of the OpenAIEmbeddings class\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "874b184f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 74;\n",
       "                var nbb_unformatted_code = \"# Use the from_texts() function to convert each document into a vector\\ndb_faiss = FAISS.from_texts(texts, embeddings)\";\n",
       "                var nbb_formatted_code = \"# Use the from_texts() function to convert each document into a vector\\ndb_faiss = FAISS.from_texts(texts, embeddings)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the from_texts() function to convert each document into a vector\n",
    "db_faiss = FAISS.from_texts(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c446909a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 77;\n",
       "                var nbb_unformatted_code = \"# Save the FAISS database to pkl object\\n# Filename\\nstr_path_output = (\\n    str_path_output_txt_en.split(\\\".\\\")[0]\\n    + \\\"db_faiss.\\\"\\n    + str_path_output_txt_en.split(\\\".\\\")[1]\\n)\\n# Store vector database\\nf_pklsave(db_faiss, str_path_output_pkl)\";\n",
       "                var nbb_formatted_code = \"# Save the FAISS database to pkl object\\n# Filename\\nstr_path_output = (\\n    str_path_output_txt_en.split(\\\".\\\")[0]\\n    + \\\"db_faiss.\\\"\\n    + str_path_output_txt_en.split(\\\".\\\")[1]\\n)\\n# Store vector database\\nf_pklsave(db_faiss, str_path_output_pkl)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the FAISS database to pkl object\n",
    "# Filename\n",
    "str_path_output = (\n",
    "    str_path_output_txt_en.split(\".\")[0]\n",
    "    + \"db_faiss.\"\n",
    "    + str_path_output_txt_en.split(\".\")[1]\n",
    ")\n",
    "# Store vector database\n",
    "f_pklsave(db_faiss, str_path_output_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df11f82",
   "metadata": {},
   "source": [
    "### Query data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0bae1de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 78;\n",
       "                var nbb_unformatted_code = \"# Create new instance of the OpenAI class\\n# llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\\nllm = OpenAI(openai_api_key=OPENAI_API_KEY)\";\n",
       "                var nbb_formatted_code = \"# Create new instance of the OpenAI class\\n# llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\\nllm = OpenAI(openai_api_key=OPENAI_API_KEY)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create new instance of the OpenAI class\n",
    "# llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "40721a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 80;\n",
       "                var nbb_unformatted_code = \"# Question that the NLP chain will attempt to answer\\nquery = \\\"What is this document about?\\\"\";\n",
       "                var nbb_formatted_code = \"# Question that the NLP chain will attempt to answer\\nquery = \\\"What is this document about?\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question that the NLP chain will attempt to answer\n",
    "query = \"What is this document about?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5712e3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 82;\n",
       "                var nbb_unformatted_code = \"# Create a retriever from the vector database\\nretriever = db_faiss.as_retriever(search_type=\\\"similarity\\\", search_kwargs={\\\"k\\\": 2})\";\n",
       "                var nbb_formatted_code = \"# Create a retriever from the vector database\\nretriever = db_faiss.as_retriever(search_type=\\\"similarity\\\", search_kwargs={\\\"k\\\": 2})\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a retriever from the vector database\n",
    "retriever = db_faiss.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f814c2",
   "metadata": {},
   "source": [
    "#### `load_qa_chain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a2d68f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 83;\n",
       "                var nbb_unformatted_code = \"# Load a pre-trained question-answering (QA) chain and creates an instance of it\\nchain = load_qa_chain(llm=llm, chain_type=\\\"stuff\\\")\";\n",
       "                var nbb_formatted_code = \"# Load a pre-trained question-answering (QA) chain and creates an instance of it\\nchain = load_qa_chain(llm=llm, chain_type=\\\"stuff\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load a pre-trained question-answering (QA) chain and creates an instance of it\n",
    "chain = load_qa_chain(llm=llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9dcbc8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 84;\n",
       "                var nbb_unformatted_code = \"# Query string as input and searches the vector database for similar documents\\n# docs variable is a list of documents that are similar to the query string, ordered by their similarity score.\\ndocs = db_faiss.similarity_search(query)\";\n",
       "                var nbb_formatted_code = \"# Query string as input and searches the vector database for similar documents\\n# docs variable is a list of documents that are similar to the query string, ordered by their similarity score.\\ndocs = db_faiss.similarity_search(query)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query string as input and searches the vector database for similar documents\n",
    "# docs variable is a list of documents that are similar to the query string, ordered by their similarity score.\n",
    "docs = db_faiss.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fea87c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This document is about the requirements and obligations of an auditing company and the Agent in regards to foreign trade, derivative instruments, prudential indicators, portfolio management, computer information processing systems, and other related operations and areas.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 85;\n",
       "                var nbb_unformatted_code = \"# Processes the input documents and the question using a pre-trained machine learning model and returns an answer to the question\\nchain.run(input_documents=docs, question=query)\";\n",
       "                var nbb_formatted_code = \"# Processes the input documents and the question using a pre-trained machine learning model and returns an answer to the question\\nchain.run(input_documents=docs, question=query)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Processes the input documents and the question using a pre-trained machine learning model and returns an answer to the question\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eff6bb",
   "metadata": {},
   "source": [
    "#### `RetrievalQA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8b3370db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 86;\n",
       "                var nbb_unformatted_code = \"# create a chain to answer questions\\nqa = RetrievalQA.from_chain_type(\\n    llm=llm, chain_type=\\\"stuff\\\", retriever=retriever, return_source_documents=True\\n)\";\n",
       "                var nbb_formatted_code = \"# create a chain to answer questions\\nqa = RetrievalQA.from_chain_type(\\n    llm=llm, chain_type=\\\"stuff\\\", retriever=retriever, return_source_documents=True\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a chain to answer questions\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b0470895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 87;\n",
       "                var nbb_unformatted_code = \"result = qa({\\\"query\\\": query})\";\n",
       "                var nbb_formatted_code = \"result = qa({\\\"query\\\": query})\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = qa({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8d64f855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"The following text document deals with foreign trade, derivative instruments, prudential indicators, portfolio management, computer information processing systems, as well as the main operations and areas that the auditing company considers most important for the Agent.\\n\\nArticle 140.- Sustentation\\n\\nIn accordance with the SMV's requirements, the auditor who has signed the opinions or reports mentioned in this title must support them before it and demonstrate that the corresponding auditing work was carried out in accordance with the Regulations.\\n\\nThe aforementioned justification and demonstration must be carried out only in the meetings that the SMV convenes or specifically sets for this purpose, and exclusively on the basis of the evaluation of the working papers that the auditor presents during them.\", metadata={}),\n",
       " Document(page_content='The means used for the delivery or making available of the documents referred to in the previous paragraph must be informed to the customer.\\n\\nIn addition to compliance with the provisions of Article 9, the Contracting Officer shall have the appropriate mechanisms in place to ensure the integrity and security of the contracting process and its subsequent verification.\\n\\nThe physical or electronic files that the Agent prepares in the performance of the obligations under this article shall be subject to the relevant legislation and made available to the SMV when so required.\\n\\nThis article is incorporated pursuant to RSUP Nº 108-2020-SMV/02.\\n\\nArticle 32 - Customer Policy', metadata={})]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 88;\n",
       "                var nbb_unformatted_code = \"retriever.get_relevant_documents(query)\";\n",
       "                var nbb_formatted_code = \"retriever.get_relevant_documents(query)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a51162e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is this document about?',\n",
       " 'result': ' This document covers foreign trade, derivative instruments, prudential indicators, portfolio management, computer information processing systems, as well as the main operations and areas that the auditing company considers most important for the Agent. It also outlines the requirements for the auditor to support their opinions and reports, as well as the mechanisms that must be in place to ensure the integrity and security of the contracting process and its subsequent verification. Finally, it includes Article 32, which outlines the customer policy.',\n",
       " 'source_documents': [Document(page_content=\"The following text document deals with foreign trade, derivative instruments, prudential indicators, portfolio management, computer information processing systems, as well as the main operations and areas that the auditing company considers most important for the Agent.\\n\\nArticle 140.- Sustentation\\n\\nIn accordance with the SMV's requirements, the auditor who has signed the opinions or reports mentioned in this title must support them before it and demonstrate that the corresponding auditing work was carried out in accordance with the Regulations.\\n\\nThe aforementioned justification and demonstration must be carried out only in the meetings that the SMV convenes or specifically sets for this purpose, and exclusively on the basis of the evaluation of the working papers that the auditor presents during them.\", metadata={}),\n",
       "  Document(page_content='The means used for the delivery or making available of the documents referred to in the previous paragraph must be informed to the customer.\\n\\nIn addition to compliance with the provisions of Article 9, the Contracting Officer shall have the appropriate mechanisms in place to ensure the integrity and security of the contracting process and its subsequent verification.\\n\\nThe physical or electronic files that the Agent prepares in the performance of the obligations under this article shall be subject to the relevant legislation and made available to the SMV when so required.\\n\\nThis article is incorporated pursuant to RSUP Nº 108-2020-SMV/02.\\n\\nArticle 32 - Customer Policy', metadata={})]}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 89;\n",
       "                var nbb_unformatted_code = \"result\";\n",
       "                var nbb_formatted_code = \"result\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf23d93f",
   "metadata": {},
   "source": [
    "#### `VectorstoreIndexCreator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d4abe8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:chromadb:Using embedded DuckDB without persistence: data will be transient\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 128;\n",
       "                var nbb_unformatted_code = \"# Create a searchable index of embeddings based on a set of input documents\\nindex_en = VectorstoreIndexCreator(\\n    # split the documents into chunks\\n    text_splitter=text_splitter,\\n    # select which embeddings we want to use\\n    embedding=embeddings,\\n    # use Chroma as the vectorestore to index and search embeddings\\n    vectorstore_cls=Chroma,\\n).from_loaders([loader_en])\";\n",
       "                var nbb_formatted_code = \"# Create a searchable index of embeddings based on a set of input documents\\nindex_en = VectorstoreIndexCreator(\\n    # split the documents into chunks\\n    text_splitter=text_splitter,\\n    # select which embeddings we want to use\\n    embedding=embeddings,\\n    # use Chroma as the vectorestore to index and search embeddings\\n    vectorstore_cls=Chroma,\\n).from_loaders([loader_en])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a searchable index of embeddings based on a set of input documents\n",
    "index_en = VectorstoreIndexCreator(\n",
    "    # split the documents into chunks\n",
    "    text_splitter=text_splitter,\n",
    "    # select which embeddings we want to use\n",
    "    embedding=embeddings,\n",
    "    # use Chroma as the vectorestore to index and search embeddings\n",
    "    vectorstore_cls=Chroma,\n",
    ").from_loaders([loader_en])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ed476b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This document is about the requirements for auditing work, customer policies, and the declaration of data accuracy for an Intermediation Agent.'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 130;\n",
       "                var nbb_unformatted_code = \"index_en.query(llm=llm, question=query, chain_type=\\\"stuff\\\")\";\n",
       "                var nbb_formatted_code = \"index_en.query(llm=llm, question=query, chain_type=\\\"stuff\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_en.query(llm=llm, question=query, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "42689f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 131;\n",
       "                var nbb_unformatted_code = \"# Question that the NLP chain will attempt to answer\\nquery = \\\"What type of firms this document talks about?\\\"\";\n",
       "                var nbb_formatted_code = \"# Question that the NLP chain will attempt to answer\\nquery = \\\"What type of firms this document talks about?\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question that the NLP chain will attempt to answer\n",
    "query = \"What type of firms this document talks about?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d234983e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This document talks about auditing firms.'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 133;\n",
       "                var nbb_unformatted_code = \"index_en.query(llm=llm, question=query, chain_type=\\\"stuff\\\")\";\n",
       "                var nbb_formatted_code = \"index_en.query(llm=llm, question=query, chain_type=\\\"stuff\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_en.query(llm=llm, question=query, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0586ff",
   "metadata": {},
   "source": [
    "## Method 2: Asking questions in spanish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdaed97",
   "metadata": {},
   "source": [
    "### Text to vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d73f3d4",
   "metadata": {},
   "source": [
    "#### Split text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d3499e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 93;\n",
       "                var nbb_unformatted_code = \"texts_es = text_splitter.split_text(str_text_raw)\";\n",
       "                var nbb_formatted_code = \"texts_es = text_splitter.split_text(str_text_raw)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts_es = text_splitter.split_text(str_text_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3a9672a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 350 document(s) in your data\n",
      "There are 306013 characters in your document\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 94;\n",
       "                var nbb_unformatted_code = \"print(f\\\"You have {len(texts)} document(s) in your data\\\")\\nprint(f\\\"There are {sum(len(i) for i in texts)} characters in your document\\\")\";\n",
       "                var nbb_formatted_code = \"print(f\\\"You have {len(texts)} document(s) in your data\\\")\\nprint(f\\\"There are {sum(len(i) for i in texts)} characters in your document\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"You have {len(texts)} document(s) in your data\")\n",
    "print(f\"There are {sum(len(i) for i in texts)} characters in your document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a48105",
   "metadata": {},
   "source": [
    "#### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "33871d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 95;\n",
       "                var nbb_unformatted_code = \"# Use the from_texts() function to convert each document into a vector\\ndb_faiss_es = FAISS.from_texts(texts, embeddings)\";\n",
       "                var nbb_formatted_code = \"# Use the from_texts() function to convert each document into a vector\\ndb_faiss_es = FAISS.from_texts(texts, embeddings)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the from_texts() function to convert each document into a vector\n",
    "db_faiss_es = FAISS.from_texts(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bbd1831d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/RSMV00001500034003', 'txt']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 96;\n",
       "                var nbb_unformatted_code = \"str_path_output_txt.split(\\\".\\\")\";\n",
       "                var nbb_formatted_code = \"str_path_output_txt.split(\\\".\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "str_path_output_txt.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2f204074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 97;\n",
       "                var nbb_unformatted_code = \"# Save the FAISS database to pkl object\\n# Filename\\nstr_path_output = str_path_output_txt.split(\\\".\\\")[0]+ \\\"db_faiss_es.pkl\\\"\\n# Store vector database\\nf_pklsave(db_faiss_es, str_path_output_pkl)\";\n",
       "                var nbb_formatted_code = \"# Save the FAISS database to pkl object\\n# Filename\\nstr_path_output = str_path_output_txt.split(\\\".\\\")[0] + \\\"db_faiss_es.pkl\\\"\\n# Store vector database\\nf_pklsave(db_faiss_es, str_path_output_pkl)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the FAISS database to pkl object\n",
    "# Filename\n",
    "str_path_output = str_path_output_txt.split(\".\")[0] + \"db_faiss_es.pkl\"\n",
    "# Store vector database\n",
    "f_pklsave(db_faiss_es, str_path_output_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ff55a4",
   "metadata": {},
   "source": [
    "### Query data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bd3a5045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 98;\n",
       "                var nbb_unformatted_code = \"# Question that the NLP chain will attempt to answer\\nquery_es = \\\"List the type of entities in the document\\\"\";\n",
       "                var nbb_formatted_code = \"# Question that the NLP chain will attempt to answer\\nquery_es = \\\"List the type of entities in the document\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question that the NLP chain will attempt to answer\n",
    "query_es = \"List the type of entities in the document\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "15bc45ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 99;\n",
       "                var nbb_unformatted_code = \"# Create a retriever from the vector database\\nretriever_es = db_faiss_es.as_retriever(search_type=\\\"similarity\\\", search_kwargs={\\\"k\\\": 2})\";\n",
       "                var nbb_formatted_code = \"# Create a retriever from the vector database\\nretriever_es = db_faiss_es.as_retriever(\\n    search_type=\\\"similarity\\\", search_kwargs={\\\"k\\\": 2}\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a retriever from the vector database\n",
    "retriever_es = db_faiss_es.as_retriever(\n",
    "    search_type=\"similarity\", search_kwargs={\"k\": 2}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc35fb2",
   "metadata": {},
   "source": [
    "#### `load_qa_chain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fa877778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 100;\n",
       "                var nbb_unformatted_code = \"# Query string as input and searches the vector database for similar documents\\n# docs variable is a list of documents that are similar to the query string, ordered by their similarity score.\\ndocs_es = db_faiss_es.similarity_search(query_es)\";\n",
       "                var nbb_formatted_code = \"# Query string as input and searches the vector database for similar documents\\n# docs variable is a list of documents that are similar to the query string, ordered by their similarity score.\\ndocs_es = db_faiss_es.similarity_search(query_es)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query string as input and searches the vector database for similar documents\n",
    "# docs variable is a list of documents that are similar to the query string, ordered by their similarity score.\n",
    "docs_es = db_faiss_es.similarity_search(query_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6f823f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Financial Instruments, Agent, Deposit or Custody Institution, Banks of the national financial system or abroad'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 101;\n",
       "                var nbb_unformatted_code = \"# Processes the input documents and the question using a pre-trained machine learning model and returns an answer to the question\\nchain.run(input_documents=docs_es, question=query_es)\";\n",
       "                var nbb_formatted_code = \"# Processes the input documents and the question using a pre-trained machine learning model and returns an answer to the question\\nchain.run(input_documents=docs_es, question=query_es)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Processes the input documents and the question using a pre-trained machine learning model and returns an answer to the question\n",
    "chain.run(input_documents=docs_es, question=query_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5499d66f",
   "metadata": {},
   "source": [
    "#### `RetrievalQA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e82941af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 106;\n",
       "                var nbb_unformatted_code = \"# Question that the NLP chain will attempt to answer\\nquery_es = \\\"Define el tipo de empresas que menciona el documento\\\"\";\n",
       "                var nbb_formatted_code = \"# Question that the NLP chain will attempt to answer\\nquery_es = \\\"Define el tipo de empresas que menciona el documento\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question that the NLP chain will attempt to answer\n",
    "query_es = \"Define el tipo de empresas que menciona el documento\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d30bcd00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 107;\n",
       "                var nbb_unformatted_code = \"# create a chain to answer questions\\nqa_es = RetrievalQA.from_chain_type(\\n    llm=llm, chain_type=\\\"stuff\\\", retriever=retriever_es, return_source_documents=True\\n)\";\n",
       "                var nbb_formatted_code = \"# create a chain to answer questions\\nqa_es = RetrievalQA.from_chain_type(\\n    llm=llm, chain_type=\\\"stuff\\\", retriever=retriever_es, return_source_documents=True\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a chain to answer questions\n",
    "qa_es = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=retriever_es, return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "360ed56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 108;\n",
       "                var nbb_unformatted_code = \"result_es = qa_es({\\\"query\\\": query_es})\";\n",
       "                var nbb_formatted_code = \"result_es = qa_es({\\\"query\\\": query_es})\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_es = qa_es({\"query\": query_es})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "43b04a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='The policy may include more than one operation of the same type corresponding to the same value, if these have been carried out on the same day, in which case, for each operation, the corresponding detail must be presented.\\n\\nThis is a text document.\\n\\nThis is a text document.\\n\\n\"(*) Paragraph modified by RSUP Nº 024-2017-SMV/01\"\\n\\nArticle 58.- Intermediation Accounts\\n\\nThe Agent must maintain at least two bank accounts for intermediation, which must be constituted in banks of the national financial system or abroad, and must be destined exclusively for their intermediation activities, one account must be destined for operations of third parties and another for operations on their own account. These accounts are used to concentrate the funds corresponding to charges and payments of customers, the own funds for operations of the Agent, which are centralized for the settlement of positions with other institutions, those coming from dividends or interests received, among others (*******).', metadata={}),\n",
       " Document(page_content=\"The following text document deals with foreign trade, derivative instruments, prudential indicators, portfolio management, computer information processing systems, as well as the main operations and areas that the auditing company considers most important for the Agent.\\n\\nArticle 140.- Sustentation\\n\\nIn accordance with the SMV's requirements, the auditor who has signed the opinions or reports mentioned in this title must support them before it and demonstrate that the corresponding auditing work was carried out in accordance with the Regulations.\\n\\nThe aforementioned justification and demonstration must be carried out only in the meetings that the SMV convenes or specifically sets for this purpose, and exclusively on the basis of the evaluation of the working papers that the auditor presents during them.\", metadata={})]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 109;\n",
       "                var nbb_unformatted_code = \"retriever_es.get_relevant_documents(query_es)\";\n",
       "                var nbb_formatted_code = \"retriever_es.get_relevant_documents(query_es)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retriever_es.get_relevant_documents(query_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6b48af99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Define el tipo de empresas que menciona el documento',\n",
       " 'result': ' El documento se refiere a los agentes de intermediación financiera.',\n",
       " 'source_documents': [Document(page_content='The policy may include more than one operation of the same type corresponding to the same value, if these have been carried out on the same day, in which case, for each operation, the corresponding detail must be presented.\\n\\nThis is a text document.\\n\\nThis is a text document.\\n\\n\"(*) Paragraph modified by RSUP Nº 024-2017-SMV/01\"\\n\\nArticle 58.- Intermediation Accounts\\n\\nThe Agent must maintain at least two bank accounts for intermediation, which must be constituted in banks of the national financial system or abroad, and must be destined exclusively for their intermediation activities, one account must be destined for operations of third parties and another for operations on their own account. These accounts are used to concentrate the funds corresponding to charges and payments of customers, the own funds for operations of the Agent, which are centralized for the settlement of positions with other institutions, those coming from dividends or interests received, among others (*******).', metadata={}),\n",
       "  Document(page_content=\"The following text document deals with foreign trade, derivative instruments, prudential indicators, portfolio management, computer information processing systems, as well as the main operations and areas that the auditing company considers most important for the Agent.\\n\\nArticle 140.- Sustentation\\n\\nIn accordance with the SMV's requirements, the auditor who has signed the opinions or reports mentioned in this title must support them before it and demonstrate that the corresponding auditing work was carried out in accordance with the Regulations.\\n\\nThe aforementioned justification and demonstration must be carried out only in the meetings that the SMV convenes or specifically sets for this purpose, and exclusively on the basis of the evaluation of the working papers that the auditor presents during them.\", metadata={})]}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 110;\n",
       "                var nbb_unformatted_code = \"result_es\";\n",
       "                var nbb_formatted_code = \"result_es\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_es"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac211a1",
   "metadata": {},
   "source": [
    "#### `VectorstoreIndexCreator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fde96356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:chromadb:Using embedded DuckDB without persistence: data will be transient\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 126;\n",
       "                var nbb_unformatted_code = \"# Create a searchable index of embeddings based on a set of input documents\\nindex = VectorstoreIndexCreator(\\n    # split the documents into chunks\\n    text_splitter=text_splitter,\\n    # select which embeddings we want to use\\n    embedding=embeddings,\\n    # use Chroma as the vectorestore to index and search embeddings\\n    vectorstore_cls=Chroma,\\n).from_loaders([loader_es])\";\n",
       "                var nbb_formatted_code = \"# Create a searchable index of embeddings based on a set of input documents\\nindex = VectorstoreIndexCreator(\\n    # split the documents into chunks\\n    text_splitter=text_splitter,\\n    # select which embeddings we want to use\\n    embedding=embeddings,\\n    # use Chroma as the vectorestore to index and search embeddings\\n    vectorstore_cls=Chroma,\\n).from_loaders([loader_es])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a searchable index of embeddings based on a set of input documents\n",
    "index = VectorstoreIndexCreator(\n",
    "    # split the documents into chunks\n",
    "    text_splitter=text_splitter,\n",
    "    # select which embeddings we want to use\n",
    "    embedding=embeddings,\n",
    "    # use Chroma as the vectorestore to index and search embeddings\n",
    "    vectorstore_cls=Chroma,\n",
    ").from_loaders([loader_es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "433d9958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' El documento se refiere a Sociedades Agentes de Bolsa, Sociedades Intermediarias de Valores, inversionistas institucionales, y algunas otras entidades financieras.'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 127;\n",
       "                var nbb_unformatted_code = \"index.query(llm=llm, question=query_es, chain_type=\\\"stuff\\\")\";\n",
       "                var nbb_formatted_code = \"index.query(llm=llm, question=query_es, chain_type=\\\"stuff\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index.query(llm=llm, question=query_es, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca78c4ab",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2711f0",
   "metadata": {},
   "source": [
    "**Open AI Cookbook**\n",
    "<br />\n",
    "<br />\n",
    "[Translate a book writen in LaTeX from Slovenian into English](https://github.com/openai/openai-cookbook/blob/main/examples/book_translation/translate_latex_book.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
